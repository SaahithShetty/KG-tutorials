{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Knowledge Graphs and Semantic Technologies -- ML4KG Tutorial\n",
    "\n",
    "\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to install pykeen beforehand, see https://pykeen.readthedocs.io/en/stable/installation.html \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pykeen\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyKeen comes with its own datasets that can be used directly in a pipeline.\n",
    "Below we import it so that we can explore it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pykeen.datasets import Nations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want to be able tfo work with our own datasets as well, so we etch the online GoT dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.triples.triples_factory:Reconstructing all label-based triples. This is expensive and rarely needed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['Abelar Hightower', 'ALLIED_WITH',\n",
       "        'House Hightower of the Hightower'],\n",
       "       ['Acorn Hall', 'SEAT_OF', 'House Smallwood of Acorn Hall'],\n",
       "       ['Addam Frey', 'ALLIED_WITH', 'House Frey of the Crossing'],\n",
       "       ['Addam Marbrand', 'ALLIED_WITH', 'House Marbrand of Ashemark'],\n",
       "       ['Addam Osgrey', 'ALLIED_WITH', 'House Osgrey of Standfast']],\n",
       "      dtype='<U44')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from pykeen import triples\n",
    "from pykeen.datasets.nations import NATIONS_TRAIN_PATH\n",
    "url = 'https://ampligraph.s3-eu-west-1.amazonaws.com/datasets/GoT.csv'\n",
    "open('GoT.csv', 'wb').write(requests.get(url).content)\n",
    "\n",
    "# Format that can be read by a pd.from_csv should also be able to be read here, but the delimiter needs to be adjusted\n",
    "# PyKEEN uses tabs as defaults\n",
    "got = triples.TriplesFactory.from_path('GoT.csv',load_triples_kwargs=dict(delimiter=','))\n",
    "got_triples = got.triples\n",
    "got_triples[:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "List the unique subject and object entities found in the dataset. Then list all of the relationships that link the entities (note that some entities are not linked). Create an RDF version of the dataset, using your own namespaces, and save is as a ttl file. \n",
    "\n",
    "Using SPARQL, answer the following questions : \n",
    "1. How many instances per class? Use ORDER BY to show the most popular class\n",
    "2. What is the most common relation per each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining train and test datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is typical in machine learning, we need to split our dataset into training and test (and sometimes validation) datasets.\n",
    "\n",
    "What differs from the standard method of randomly sampling N points to make up our test set, is that our data points are two entities linked by some relationship, and we need to take care to ensure that all entities are represented in train and test sets by at least one triple.\n",
    "\n",
    "To accomplish this, PyKEEN provides the <b>pykeen.triples.TriplesFactory.split()</b> function, which defaults to an 80/20 split. It is also by default stratified, to ensure that the distribution of the test set corresponds to that of the training set. If you want to use early stopping, you will also need a validation set. The function takes a list of percentages as argument: if you want a 95/5 split you give it <b>[0.95,0.05]</b> as argument, if you want 90/5/5 (which would include a validation set as well) you give it <b>[0.9,0.05,0.05]</b> as argument and it will return 3 datasets.\n",
    "\n",
    "For sake of example, we will create a small test size that includes only 5% of triples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.utils:using automatically assigned random_state=341877703\n",
      "INFO:pykeen.triples.splitting:done splitting triples to groups of sizes [1003, 159]\n",
      "WARNING:pykeen.triples.triples_factory:Reconstructing all label-based triples. This is expensive and rarely needed.\n",
      "WARNING:pykeen.triples.triples_factory:Reconstructing all label-based triples. This is expensive and rarely needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:  (3016, 3)\n",
      "Test set size:  (159, 3)\n"
     ]
    }
   ],
   "source": [
    "# got_training, got_testing = got.split()\n",
    "got_training, got_testing = got.split([0.95,0.05])\n",
    "\n",
    "print('Train set size: ', got_training.triples.shape)\n",
    "print('Test set size: ', got_testing.triples.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Create three train-test sets of different sizes from the GoT data. Give them different names. Make sure the test set is not too big when compared to the training set (test set should be max 15% of the total dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyKEEN has implemented several Knoweldge Graph Embedding models (TransE, ComplEx, DistMult, HolE, etc.). We will use the ComplEx model with default values for this tutorial.\n",
    "\n",
    "You can find the list of all implemented models in the documentation: https://pykeen.readthedocs.io/en/stable/reference/models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing a model and instantiate it:\n",
    "There are two ways to import and use a model, both are shown below and don't give different results but not importing the model before hand might cause the automatic importing to be slower, especially if you plan to use the same model multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No cuda devices were available. The model runs on CPU\n",
      "Training epochs on cpu: 100%|██████████| 5/5 [00:00<00:00,  6.05epoch/s, loss=15.5, prev_loss=16]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/80.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 80.0/80.0 [00:00<00:00, 4.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Losses Plot'}, xlabel='Epoch', ylabel='marginranking Loss'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wee need the pipeline to run a model, so it is simpler to import it directly.\n",
    "# Pykeen lets you train a model with the minimal amount of custom parameters\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "# here we don't import the model, but let PyKEEN do the importing.\n",
    "pipeline_result_simple = pipeline(\n",
    "    random_seed=0,\n",
    "    model='ComplEx',\n",
    "    training=got_training,\n",
    "    testing=got_testing,\n",
    ")\n",
    "pipeline_result_simple.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 5/5 [00:00<00:00,  6.88epoch/s, loss=15.5, prev_loss=16]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/80.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 80.0/80.0 [00:00<00:00, 5.10ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.02s seconds\n",
      "/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Losses Plot'}, xlabel='Epoch', ylabel='marginranking Loss'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here we import the model and use it directly.\n",
    "from pykeen.models import ComplEx\n",
    "\n",
    "pipeline_result_imported = pipeline(\n",
    "    random_seed=0,\n",
    "    model=ComplEx,\n",
    "    training=got_training,\n",
    "    testing=got_testing,\n",
    ")\n",
    "pipeline_result_imported.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve different metrics from the results. Here we retrieve the mean reciprocal rank (MRR). The result is the same for both the simple and imported model, because we used the same random seed (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3374660313129425\n",
      "0.3374660313129425\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_result_imported.get_metric('mrr'))\n",
    "print(pipeline_result_simple.get_metric('mrr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:27<00:00,  7.35epoch/s, loss=2.04, prev_loss=2.14]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/80.0 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 80.0/80.0 [00:00<00:00, 2.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.06s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34232959151268005\n"
     ]
    }
   ],
   "source": [
    "# but to get a better performing model, you want to set different things\n",
    "pipeline_result = pipeline(\n",
    "    random_seed=0,\n",
    "    model='ComplEx',\n",
    "    training=got_training,\n",
    "    testing=got_testing,\n",
    "    epochs=200,\n",
    "    dimensions=150,\n",
    "    optimizer='adam',\n",
    "    optimizer_kwargs={'lr':1e-3},\n",
    "    loss='pairwisehinge', \n",
    "    regularizer='LP', \n",
    "    regularizer_kwargs={'p':3, 'weight':1e-5}, \n",
    ")\n",
    "print(pipeline_result.get_metric('mrr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the parameters:\n",
    "\n",
    "- dimensions : the dimensionality of the embedding space\n",
    "- negative_sampler : the negative samplic strategy, here set to default (not used in arguments).\n",
    "- batch_size : the number of batches in which the training set is split during the training loop. If you are having into low memory issues than settings this to a higher number may help.\n",
    "- epochs : the number of epochs to train the model for.\n",
    "- optimizer : the Adam optimizer, with a learning rate of $1e-3$ set via the <i>optimizer_kwarg</i>.\n",
    "- loss : pairwise loss, with a margin of $0.5$ set via the <i>loss_kwarg</i>.\n",
    "- regularizer :  regularization with $p=2$, i.e. $l_2$ regularization. $\\lambda$ = $1e-5$, set via the <i>regularizer_kwarg</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Negatives\n",
    "\n",
    "To ensure our model can be trained and evaluated correctly, we need to define a filter to ensure that no negative statements generated by the corruption procedure are actually positives. This is simply done by concatenating train and test sets. When negative triples are generated by the corruption strategy, we can check that they aren't actually true statements.\n",
    "\n",
    "With PyKEEN this is made very easy, and can simply be passed as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1055304007.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:38<00:00,  5.26epoch/s, loss=0.202, prev_loss=0.278]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/159 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 159/159 [00:00<00:00, 916triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025822946336120367\n"
     ]
    }
   ],
   "source": [
    "pipeline_result = pipeline(\n",
    "    model='ComplEx',\n",
    "    training=got_training,\n",
    "    testing=got_testing,\n",
    "    epochs=200,\n",
    "    dimensions=150,\n",
    "    optimizer='adam',\n",
    "    optimizer_kwargs={'lr':1e-3},\n",
    "    loss='pairwisehinge', \n",
    "    regularizer='LP', \n",
    "    regularizer_kwargs={'p':3, 'weight':1e-5}, \n",
    "    \n",
    "    negative_sampler='basic',\n",
    "    negative_sampler_kwargs=dict(\n",
    "        filtered=True,\n",
    "    )\n",
    ")\n",
    "print(pipeline_result.get_metric('mrr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save your learned model and also the results, we need to add checkpoints to the pipeline.\n",
    "By adding training kwargs to the pipeline, the model will be automatically saved. By default, it saves the model after every epoch (checkpoint_frequency=0). You can also set the directory to which the models are saved, but by default they will end up in ~/.data/pykeen/checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:loaded random seed 242643974 from checkpoint.\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "INFO:pykeen.training.training_loop:=> loading checkpoint 'checkpoint_dir/got_complex_checkpoint.pt'\n",
      "INFO:pykeen.training.training_loop:=> loaded checkpoint 'checkpoint_dir/got_complex_checkpoint.pt' stopped after having finished epoch 200\n",
      "INFO:pykeen.stoppers.stopper:=> loading stopper summary dict from training loop checkpoint in 'checkpoint_dir/got_complex_checkpoint.pt'\n",
      "INFO:pykeen.stoppers.stopper:=> loaded stopper summary dictionary from checkpoint in 'checkpoint_dir/got_complex_checkpoint.pt'\n",
      "WARNING:pykeen.training.training_loop:the training loop was configured with a stopper but no stopper configuration was saved in the checkpoint\n",
      "Training epochs on cuda:0: 100%|███████████████████████████████████████████████████████████| 200/200 [00:00<?, ?epoch/s]\n",
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=159.\n",
      "Evaluating on cuda:0: 100%|███████████████████████████████████████████████████████| 159/159 [00:00<00:00, 2.34ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.08s seconds\n"
     ]
    }
   ],
   "source": [
    "pipeline_result = pipeline(\n",
    "    model='ComplEx',\n",
    "    training=got_training,\n",
    "    testing=got_testing,\n",
    "    training_kwargs=dict(\n",
    "        num_epochs=200,\n",
    "        checkpoint_name='got_complex_checkpoint.pt',\n",
    "        checkpoint_directory='checkpoint_dir/',\n",
    "        checkpoint_frequency=20,\n",
    "    ),\n",
    "    dimensions=150,\n",
    "    optimizer='adam',\n",
    "    optimizer_kwargs={'lr':1e-3},\n",
    "    loss='pairwisehinge', \n",
    "    regularizer='LP', \n",
    "    regularizer_kwargs={'p':3, 'weight':1e-5}, \n",
    "    negative_sampler='basic',\n",
    "    negative_sampler_kwargs=dict(\n",
    "        filtered=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another way to save models, but for that we need to do the training and evaluating outside of the pipeline model. Below is an example of the above model training outside of the pipeline module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.models.base:No random seed is specified. This may lead to non-reproducible results.\n",
      "INFO:pykeen.training.training_loop:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value '{batch_size}'\n",
      "Training epochs on cpu:   0%|                                                                | 0/200 [00:00<?, ?epoch/s]\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 92.13batch/s]\u001b[A\n",
      "Training epochs on cpu:   0%|▏                             | 1/200 [00:00<00:41,  4.81epoch/s, loss=11.4, prev_loss=nan]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   1%|▎                              | 2/200 [00:00<00:33,  5.86epoch/s, loss=11, prev_loss=11.4]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%|▍                              | 3/200 [00:00<00:33,  5.90epoch/s, loss=10.6, prev_loss=11]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%|▌                            | 4/200 [00:00<00:33,  5.79epoch/s, loss=10.1, prev_loss=10.6]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 93.22batch/s]\u001b[A\n",
      "Training epochs on cpu:   2%|▋                            | 5/200 [00:00<00:36,  5.39epoch/s, loss=9.93, prev_loss=10.1]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   3%|▊                            | 6/200 [00:01<00:34,  5.68epoch/s, loss=9.32, prev_loss=9.93]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%|█                            | 7/200 [00:01<00:33,  5.80epoch/s, loss=8.93, prev_loss=9.32]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%|█▏                           | 8/200 [00:01<00:32,  5.99epoch/s, loss=8.94, prev_loss=8.93]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   4%|█▎                           | 9/200 [00:01<00:30,  6.21epoch/s, loss=8.79, prev_loss=8.94]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   5%|█▍                          | 10/200 [00:01<00:30,  6.30epoch/s, loss=8.29, prev_loss=8.79]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%|█▌                          | 11/200 [00:01<00:30,  6.29epoch/s, loss=8.19, prev_loss=8.29]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%|█▋                          | 12/200 [00:01<00:29,  6.36epoch/s, loss=8.08, prev_loss=8.19]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   6%|█▊                          | 13/200 [00:02<00:29,  6.34epoch/s, loss=7.63, prev_loss=8.08]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   7%|█▉                          | 14/200 [00:02<00:29,  6.30epoch/s, loss=7.67, prev_loss=7.63]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%|██▏                          | 15/200 [00:02<00:29,  6.30epoch/s, loss=7.5, prev_loss=7.67]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 93.60batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%|██▎                          | 16/200 [00:02<00:31,  5.81epoch/s, loss=7.21, prev_loss=7.5]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   8%|██▍                          | 17/200 [00:02<00:30,  6.03epoch/s, loss=7.4, prev_loss=7.21]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:   9%|██▌                          | 18/200 [00:02<00:29,  6.11epoch/s, loss=7.02, prev_loss=7.4]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%|██▋                         | 19/200 [00:03<00:29,  6.17epoch/s, loss=6.82, prev_loss=7.02]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 117.11batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%|██▊                         | 20/200 [00:03<00:30,  5.98epoch/s, loss=6.32, prev_loss=6.82]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 118.14batch/s]\u001b[A\n",
      "Training epochs on cpu:  10%|██▉                         | 21/200 [00:03<00:30,  5.84epoch/s, loss=6.52, prev_loss=6.32]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 96.34batch/s]\u001b[A\n",
      "Training epochs on cpu:  11%|███▏                         | 22/200 [00:03<00:32,  5.50epoch/s, loss=6.6, prev_loss=6.52]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%|███▎                         | 23/200 [00:03<00:31,  5.67epoch/s, loss=6.25, prev_loss=6.6]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 99.15batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%|███▎                        | 24/200 [00:04<00:32,  5.42epoch/s, loss=6.45, prev_loss=6.25]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  75%|██████████████████████████████████████████              | 9/12 [00:00<00:00, 87.84batch/s]\u001b[A\n",
      "Training epochs on cpu:  12%|███▌                        | 25/200 [00:04<00:34,  5.12epoch/s, loss=6.15, prev_loss=6.45]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  13%|███▋                        | 26/200 [00:04<00:32,  5.31epoch/s, loss=5.98, prev_loss=6.15]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 105.28batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|███▊                        | 27/200 [00:04<00:32,  5.27epoch/s, loss=6.08, prev_loss=5.98]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 112.54batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|███▉                        | 28/200 [00:04<00:32,  5.32epoch/s, loss=5.92, prev_loss=6.08]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  14%|████                        | 29/200 [00:05<00:30,  5.52epoch/s, loss=5.64, prev_loss=5.92]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  15%|████▏                       | 30/200 [00:05<00:29,  5.83epoch/s, loss=5.75, prev_loss=5.64]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|████▎                       | 31/200 [00:05<00:27,  6.05epoch/s, loss=5.67, prev_loss=5.75]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|████▍                       | 32/200 [00:05<00:27,  6.13epoch/s, loss=5.41, prev_loss=5.67]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 98.84batch/s]\u001b[A\n",
      "Training epochs on cpu:  16%|████▌                       | 33/200 [00:05<00:28,  5.77epoch/s, loss=5.52, prev_loss=5.41]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  17%|████▊                       | 34/200 [00:05<00:27,  5.95epoch/s, loss=5.53, prev_loss=5.52]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|████▉                       | 35/200 [00:05<00:27,  6.09epoch/s, loss=5.33, prev_loss=5.53]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 112.02batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|█████                       | 36/200 [00:06<00:27,  5.88epoch/s, loss=5.29, prev_loss=5.33]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  18%|█████▏                      | 37/200 [00:06<00:26,  6.05epoch/s, loss=5.22, prev_loss=5.29]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 106.36batch/s]\u001b[A\n",
      "Training epochs on cpu:  19%|█████▎                      | 38/200 [00:06<00:28,  5.67epoch/s, loss=5.34, prev_loss=5.22]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|█████▍                      | 39/200 [00:06<00:28,  5.70epoch/s, loss=5.27, prev_loss=5.34]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 96.19batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|█████▌                      | 40/200 [00:06<00:29,  5.43epoch/s, loss=5.07, prev_loss=5.27]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 95.85batch/s]\u001b[A\n",
      "Training epochs on cpu:  20%|█████▋                      | 41/200 [00:07<00:30,  5.25epoch/s, loss=5.13, prev_loss=5.07]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  21%|██████                       | 42/200 [00:07<00:29,  5.44epoch/s, loss=5.2, prev_loss=5.13]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|██████▏                      | 43/200 [00:07<00:27,  5.69epoch/s, loss=5.14, prev_loss=5.2]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 93.44batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|██████▏                     | 44/200 [00:07<00:28,  5.46epoch/s, loss=4.98, prev_loss=5.14]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  22%|██████▎                     | 45/200 [00:07<00:27,  5.66epoch/s, loss=5.16, prev_loss=4.98]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  23%|██████▍                     | 46/200 [00:07<00:26,  5.85epoch/s, loss=5.07, prev_loss=5.16]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|██████▌                     | 47/200 [00:08<00:25,  5.99epoch/s, loss=4.93, prev_loss=5.07]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|██████▋                     | 48/200 [00:08<00:25,  5.89epoch/s, loss=4.98, prev_loss=4.93]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  24%|██████▊                     | 49/200 [00:08<00:25,  5.87epoch/s, loss=5.06, prev_loss=4.98]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  25%|███████                     | 50/200 [00:08<00:25,  5.97epoch/s, loss=4.88, prev_loss=5.06]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 98.32batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|███████▏                    | 51/200 [00:08<00:26,  5.60epoch/s, loss=5.16, prev_loss=4.88]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|███████▎                    | 52/200 [00:08<00:25,  5.70epoch/s, loss=4.81, prev_loss=5.16]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  26%|███████▍                    | 53/200 [00:09<00:25,  5.84epoch/s, loss=4.85, prev_loss=4.81]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  27%|███████▌                    | 54/200 [00:09<00:24,  5.98epoch/s, loss=4.73, prev_loss=4.85]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|███████▋                    | 55/200 [00:09<00:24,  5.91epoch/s, loss=5.09, prev_loss=4.73]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|███████▊                    | 56/200 [00:09<00:24,  5.84epoch/s, loss=4.84, prev_loss=5.09]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  28%|███████▉                    | 57/200 [00:09<00:24,  5.87epoch/s, loss=4.85, prev_loss=4.84]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 114.77batch/s]\u001b[A\n",
      "Training epochs on cpu:  29%|████████                    | 58/200 [00:10<00:24,  5.69epoch/s, loss=4.85, prev_loss=4.85]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|████████▎                   | 59/200 [00:10<00:24,  5.71epoch/s, loss=4.65, prev_loss=4.85]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|████████▍                   | 60/200 [00:10<00:23,  5.84epoch/s, loss=4.56, prev_loss=4.65]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  30%|████████▌                   | 61/200 [00:10<00:23,  5.86epoch/s, loss=4.86, prev_loss=4.56]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 108.03batch/s]\u001b[A\n",
      "Training epochs on cpu:  31%|████████▋                   | 62/200 [00:10<00:24,  5.66epoch/s, loss=4.52, prev_loss=4.86]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|████████▊                   | 63/200 [00:10<00:23,  5.83epoch/s, loss=4.72, prev_loss=4.52]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|█████████▎                   | 64/200 [00:11<00:23,  5.83epoch/s, loss=4.6, prev_loss=4.72]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  32%|█████████▍                   | 65/200 [00:11<00:22,  5.99epoch/s, loss=4.66, prev_loss=4.6]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  33%|█████████▏                  | 66/200 [00:11<00:22,  6.07epoch/s, loss=4.61, prev_loss=4.66]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|█████████▋                   | 67/200 [00:11<00:22,  6.03epoch/s, loss=4.7, prev_loss=4.61]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|██████████▏                   | 68/200 [00:11<00:21,  6.22epoch/s, loss=4.7, prev_loss=4.7]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  34%|██████████                   | 69/200 [00:11<00:21,  6.22epoch/s, loss=4.53, prev_loss=4.7]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  35%|█████████▊                  | 70/200 [00:11<00:20,  6.32epoch/s, loss=4.65, prev_loss=4.53]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|█████████▉                  | 71/200 [00:12<00:21,  6.13epoch/s, loss=4.76, prev_loss=4.65]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|██████████                  | 72/200 [00:12<00:20,  6.18epoch/s, loss=4.64, prev_loss=4.76]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  36%|██████████▏                 | 73/200 [00:12<00:20,  6.07epoch/s, loss=4.38, prev_loss=4.64]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 119.82batch/s]\u001b[A\n",
      "Training epochs on cpu:  37%|██████████▎                 | 74/200 [00:12<00:21,  5.93epoch/s, loss=4.53, prev_loss=4.38]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|██████████▌                 | 75/200 [00:12<00:20,  6.08epoch/s, loss=4.63, prev_loss=4.53]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|██████████▋                 | 76/200 [00:12<00:20,  6.13epoch/s, loss=4.33, prev_loss=4.63]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 119.56batch/s]\u001b[A\n",
      "Training epochs on cpu:  38%|██████████▊                 | 77/200 [00:13<00:20,  5.97epoch/s, loss=4.58, prev_loss=4.33]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 100.13batch/s]\u001b[A\n",
      "Training epochs on cpu:  39%|██████████▉                 | 78/200 [00:13<00:21,  5.66epoch/s, loss=4.78, prev_loss=4.58]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 108.26batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|███████████                 | 79/200 [00:13<00:21,  5.53epoch/s, loss=4.45, prev_loss=4.78]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|███████████▏                | 80/200 [00:13<00:20,  5.78epoch/s, loss=4.45, prev_loss=4.45]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 101.33batch/s]\u001b[A\n",
      "Training epochs on cpu:  40%|███████████▋                 | 81/200 [00:13<00:21,  5.57epoch/s, loss=4.5, prev_loss=4.45]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  41%|███████████▉                 | 82/200 [00:14<00:20,  5.84epoch/s, loss=4.48, prev_loss=4.5]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  42%|███████████▌                | 83/200 [00:14<00:19,  6.00epoch/s, loss=4.58, prev_loss=4.48]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  42%|███████████▊                | 84/200 [00:14<00:19,  6.01epoch/s, loss=4.36, prev_loss=4.58]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  42%|███████████▉                | 85/200 [00:14<00:18,  6.06epoch/s, loss=4.24, prev_loss=4.36]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  43%|████████████                | 86/200 [00:14<00:19,  5.99epoch/s, loss=4.33, prev_loss=4.24]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 112.24batch/s]\u001b[A\n",
      "Training epochs on cpu:  44%|████████████▏               | 87/200 [00:14<00:19,  5.82epoch/s, loss=4.52, prev_loss=4.33]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  44%|████████████▎               | 88/200 [00:15<00:18,  6.03epoch/s, loss=4.42, prev_loss=4.52]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  44%|████████████▍               | 89/200 [00:15<00:17,  6.17epoch/s, loss=4.21, prev_loss=4.42]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  45%|█████████████                | 90/200 [00:15<00:17,  6.16epoch/s, loss=4.5, prev_loss=4.21]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  46%|█████████████▏               | 91/200 [00:15<00:17,  6.29epoch/s, loss=4.22, prev_loss=4.5]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 111.44batch/s]\u001b[A\n",
      "Training epochs on cpu:  46%|████████████▉               | 92/200 [00:15<00:18,  5.95epoch/s, loss=4.34, prev_loss=4.22]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  46%|█████████████               | 93/200 [00:15<00:18,  5.90epoch/s, loss=4.27, prev_loss=4.34]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 112.14batch/s]\u001b[A\n",
      "Training epochs on cpu:  47%|█████████████▏              | 94/200 [00:16<00:18,  5.76epoch/s, loss=4.29, prev_loss=4.27]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 98.22batch/s]\u001b[A\n",
      "Training epochs on cpu:  48%|█████████████▊               | 95/200 [00:16<00:19,  5.45epoch/s, loss=4.2, prev_loss=4.29]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  48%|█████████████▉               | 96/200 [00:16<00:18,  5.54epoch/s, loss=4.54, prev_loss=4.2]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  48%|█████████████▌              | 97/200 [00:16<00:18,  5.71epoch/s, loss=4.12, prev_loss=4.54]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  49%|█████████████▋              | 98/200 [00:16<00:17,  5.76epoch/s, loss=4.32, prev_loss=4.12]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  50%|█████████████▊              | 99/200 [00:16<00:17,  5.92epoch/s, loss=4.18, prev_loss=4.32]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  50%|█████████████▌             | 100/200 [00:17<00:16,  5.93epoch/s, loss=3.97, prev_loss=4.18]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  50%|█████████████▋             | 101/200 [00:17<00:16,  6.04epoch/s, loss=4.23, prev_loss=3.97]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  51%|█████████████▊             | 102/200 [00:17<00:15,  6.22epoch/s, loss=3.97, prev_loss=4.23]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  52%|█████████████▉             | 103/200 [00:17<00:15,  6.30epoch/s, loss=4.29, prev_loss=3.97]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  52%|██████████████             | 104/200 [00:17<00:15,  6.16epoch/s, loss=4.14, prev_loss=4.29]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  52%|██████████████▏            | 105/200 [00:17<00:15,  6.19epoch/s, loss=4.09, prev_loss=4.14]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  53%|██████████████▎            | 106/200 [00:18<00:14,  6.29epoch/s, loss=4.15, prev_loss=4.09]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  54%|██████████████▍            | 107/200 [00:18<00:14,  6.26epoch/s, loss=4.11, prev_loss=4.15]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  54%|██████████████▌            | 108/200 [00:18<00:15,  6.12epoch/s, loss=4.23, prev_loss=4.11]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 109.74batch/s]\u001b[A\n",
      "Training epochs on cpu:  55%|██████████████▋            | 109/200 [00:18<00:15,  5.82epoch/s, loss=4.04, prev_loss=4.23]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  55%|██████████████▊            | 110/200 [00:18<00:15,  5.81epoch/s, loss=3.94, prev_loss=4.04]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  56%|██████████████▉            | 111/200 [00:18<00:14,  6.01epoch/s, loss=4.05, prev_loss=3.94]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  56%|███████████████            | 112/200 [00:19<00:14,  5.93epoch/s, loss=4.04, prev_loss=4.05]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  56%|███████████████▎           | 113/200 [00:19<00:14,  6.00epoch/s, loss=4.14, prev_loss=4.04]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 112.85batch/s]\u001b[A\n",
      "Training epochs on cpu:  57%|███████████████▍           | 114/200 [00:19<00:14,  5.82epoch/s, loss=3.86, prev_loss=4.14]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 99.12batch/s]\u001b[A\n",
      "Training epochs on cpu:  57%|███████████████▌           | 115/200 [00:19<00:15,  5.58epoch/s, loss=3.81, prev_loss=3.86]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  58%|███████████████▋           | 116/200 [00:19<00:14,  5.74epoch/s, loss=3.95, prev_loss=3.81]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  58%|███████████████▊           | 117/200 [00:19<00:14,  5.72epoch/s, loss=4.13, prev_loss=3.95]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 117.64batch/s]\u001b[A\n",
      "Training epochs on cpu:  59%|███████████████▉           | 118/200 [00:20<00:14,  5.68epoch/s, loss=4.15, prev_loss=4.13]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  60%|████████████████           | 119/200 [00:20<00:13,  5.82epoch/s, loss=3.94, prev_loss=4.15]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  60%|████████████████▏          | 120/200 [00:20<00:13,  5.97epoch/s, loss=3.98, prev_loss=3.94]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 108.19batch/s]\u001b[A\n",
      "Training epochs on cpu:  60%|████████████████▎          | 121/200 [00:20<00:13,  5.68epoch/s, loss=3.94, prev_loss=3.98]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  61%|████████████████▍          | 122/200 [00:20<00:13,  5.83epoch/s, loss=3.74, prev_loss=3.94]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 98.39batch/s]\u001b[A\n",
      "Training epochs on cpu:  62%|████████████████▌          | 123/200 [00:21<00:13,  5.54epoch/s, loss=3.87, prev_loss=3.74]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  62%|████████████████▋          | 124/200 [00:21<00:13,  5.69epoch/s, loss=3.58, prev_loss=3.87]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  62%|████████████████▉          | 125/200 [00:21<00:13,  5.73epoch/s, loss=3.87, prev_loss=3.58]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  63%|█████████████████          | 126/200 [00:21<00:12,  5.81epoch/s, loss=3.81, prev_loss=3.87]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  64%|█████████████████▏         | 127/200 [00:21<00:12,  5.85epoch/s, loss=3.78, prev_loss=3.81]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  64%|█████████████████▎         | 128/200 [00:21<00:11,  6.00epoch/s, loss=3.85, prev_loss=3.78]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 110.69batch/s]\u001b[A\n",
      "Training epochs on cpu:  64%|█████████████████▍         | 129/200 [00:22<00:12,  5.81epoch/s, loss=4.04, prev_loss=3.85]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  65%|█████████████████▌         | 130/200 [00:22<00:11,  6.01epoch/s, loss=3.66, prev_loss=4.04]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  66%|█████████████████▋         | 131/200 [00:22<00:11,  5.95epoch/s, loss=3.68, prev_loss=3.66]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  66%|█████████████████▊         | 132/200 [00:22<00:11,  6.09epoch/s, loss=3.59, prev_loss=3.68]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  66%|█████████████████▉         | 133/200 [00:22<00:11,  6.08epoch/s, loss=3.64, prev_loss=3.59]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  67%|██████████████████         | 134/200 [00:22<00:10,  6.01epoch/s, loss=3.76, prev_loss=3.64]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  68%|██████████████████▏        | 135/200 [00:22<00:10,  6.17epoch/s, loss=3.59, prev_loss=3.76]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  68%|██████████████████▎        | 136/200 [00:23<00:10,  6.20epoch/s, loss=3.71, prev_loss=3.59]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  68%|██████████████████▍        | 137/200 [00:23<00:10,  6.07epoch/s, loss=3.63, prev_loss=3.71]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  69%|██████████████████▋        | 138/200 [00:23<00:10,  6.19epoch/s, loss=3.56, prev_loss=3.63]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  70%|██████████████████▊        | 139/200 [00:23<00:09,  6.28epoch/s, loss=3.73, prev_loss=3.56]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  70%|██████████████████▉        | 140/200 [00:23<00:09,  6.16epoch/s, loss=3.58, prev_loss=3.73]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  70%|███████████████████        | 141/200 [00:23<00:09,  6.35epoch/s, loss=3.57, prev_loss=3.58]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  71%|███████████████████▏       | 142/200 [00:24<00:09,  6.34epoch/s, loss=3.57, prev_loss=3.57]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  72%|███████████████████▎       | 143/200 [00:24<00:09,  6.18epoch/s, loss=3.66, prev_loss=3.57]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 114.45batch/s]\u001b[A\n",
      "Training epochs on cpu:  72%|███████████████████▍       | 144/200 [00:24<00:09,  5.96epoch/s, loss=3.55, prev_loss=3.66]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  72%|███████████████████▌       | 145/200 [00:24<00:09,  6.04epoch/s, loss=3.59, prev_loss=3.55]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  73%|███████████████████▋       | 146/200 [00:24<00:08,  6.23epoch/s, loss=3.61, prev_loss=3.59]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 115.96batch/s]\u001b[A\n",
      "Training epochs on cpu:  74%|███████████████████▊       | 147/200 [00:24<00:08,  5.98epoch/s, loss=3.48, prev_loss=3.61]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  74%|███████████████████▉       | 148/200 [00:25<00:08,  6.07epoch/s, loss=3.49, prev_loss=3.48]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  74%|████████████████████       | 149/200 [00:25<00:08,  6.12epoch/s, loss=3.61, prev_loss=3.49]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  75%|█████████████████████       | 150/200 [00:25<00:08,  6.14epoch/s, loss=3.6, prev_loss=3.61]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  76%|█████████████████████▏      | 151/200 [00:25<00:07,  6.26epoch/s, loss=3.55, prev_loss=3.6]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  76%|████████████████████▌      | 152/200 [00:25<00:07,  6.35epoch/s, loss=3.41, prev_loss=3.55]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 94.94batch/s]\u001b[A\n",
      "Training epochs on cpu:  76%|████████████████████▋      | 153/200 [00:25<00:08,  5.84epoch/s, loss=3.48, prev_loss=3.41]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 118.11batch/s]\u001b[A\n",
      "Training epochs on cpu:  77%|████████████████████▊      | 154/200 [00:26<00:08,  5.73epoch/s, loss=3.42, prev_loss=3.48]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  78%|████████████████████▉      | 155/200 [00:26<00:07,  5.85epoch/s, loss=3.43, prev_loss=3.42]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  78%|█████████████████████      | 156/200 [00:26<00:07,  5.97epoch/s, loss=3.23, prev_loss=3.43]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  78%|█████████████████████▏     | 157/200 [00:26<00:07,  6.03epoch/s, loss=3.43, prev_loss=3.23]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 103.36batch/s]\u001b[A\n",
      "Training epochs on cpu:  79%|█████████████████████▎     | 158/200 [00:26<00:07,  5.66epoch/s, loss=3.57, prev_loss=3.43]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  80%|██████████████████████▎     | 159/200 [00:26<00:07,  5.84epoch/s, loss=3.5, prev_loss=3.57]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 118.16batch/s]\u001b[A\n",
      "Training epochs on cpu:  80%|██████████████████████▍     | 160/200 [00:27<00:06,  5.75epoch/s, loss=3.43, prev_loss=3.5]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  80%|█████████████████████▋     | 161/200 [00:27<00:06,  5.82epoch/s, loss=3.29, prev_loss=3.43]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  81%|█████████████████████▊     | 162/200 [00:27<00:06,  6.08epoch/s, loss=3.31, prev_loss=3.29]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  82%|██████████████████████▊     | 163/200 [00:27<00:06,  5.95epoch/s, loss=3.6, prev_loss=3.31]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  82%|██████████████████████▉     | 164/200 [00:27<00:05,  6.08epoch/s, loss=3.25, prev_loss=3.6]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  82%|███████████████████████     | 165/200 [00:27<00:05,  6.16epoch/s, loss=3.3, prev_loss=3.25]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 115.67batch/s]\u001b[A\n",
      "Training epochs on cpu:  83%|███████████████████████▏    | 166/200 [00:28<00:05,  5.94epoch/s, loss=3.45, prev_loss=3.3]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 118.71batch/s]\u001b[A\n",
      "Training epochs on cpu:  84%|██████████████████████▌    | 167/200 [00:28<00:05,  5.80epoch/s, loss=3.22, prev_loss=3.45]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  84%|███████████████████████▌    | 168/200 [00:28<00:05,  5.98epoch/s, loss=3.3, prev_loss=3.22]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  84%|███████████████████████▋    | 169/200 [00:28<00:05,  5.89epoch/s, loss=3.36, prev_loss=3.3]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  85%|██████████████████████▉    | 170/200 [00:28<00:05,  5.97epoch/s, loss=3.25, prev_loss=3.36]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 114.35batch/s]\u001b[A\n",
      "Training epochs on cpu:  86%|███████████████████████    | 171/200 [00:28<00:05,  5.75epoch/s, loss=3.15, prev_loss=3.25]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 106.91batch/s]\u001b[A\n",
      "Training epochs on cpu:  86%|███████████████████████▏   | 172/200 [00:29<00:05,  5.59epoch/s, loss=3.16, prev_loss=3.15]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  86%|████████████████████████▏   | 173/200 [00:29<00:04,  5.80epoch/s, loss=3.1, prev_loss=3.16]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  87%|████████████████████████▎   | 174/200 [00:29<00:04,  5.96epoch/s, loss=3.12, prev_loss=3.1]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  88%|███████████████████████▋   | 175/200 [00:29<00:04,  6.07epoch/s, loss=3.34, prev_loss=3.12]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  88%|███████████████████████▊   | 176/200 [00:29<00:03,  6.17epoch/s, loss=3.27, prev_loss=3.34]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 118.50batch/s]\u001b[A\n",
      "Training epochs on cpu:  88%|███████████████████████▉   | 177/200 [00:29<00:03,  5.96epoch/s, loss=3.23, prev_loss=3.27]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  89%|████████████████████████   | 178/200 [00:30<00:03,  6.05epoch/s, loss=3.19, prev_loss=3.23]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  90%|████████████████████████▏  | 179/200 [00:30<00:03,  6.20epoch/s, loss=3.08, prev_loss=3.19]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  90%|█████████████████████████▏  | 180/200 [00:30<00:03,  6.09epoch/s, loss=3.2, prev_loss=3.08]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  90%|█████████████████████████▎  | 181/200 [00:30<00:03,  6.08epoch/s, loss=3.09, prev_loss=3.2]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  91%|████████████████████████▌  | 182/200 [00:30<00:02,  6.23epoch/s, loss=3.05, prev_loss=3.09]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 102.92batch/s]\u001b[A\n",
      "Training epochs on cpu:  92%|████████████████████████▋  | 183/200 [00:30<00:02,  5.84epoch/s, loss=3.04, prev_loss=3.05]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|█████████████████████████████████████████████▊         | 10/12 [00:00<00:00, 99.11batch/s]\u001b[A\n",
      "Training epochs on cpu:  92%|████████████████████████▊  | 184/200 [00:31<00:02,  5.57epoch/s, loss=3.01, prev_loss=3.04]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  92%|████████████████████████▉  | 185/200 [00:31<00:02,  5.75epoch/s, loss=2.84, prev_loss=3.01]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 119.22batch/s]\u001b[A\n",
      "Training epochs on cpu:  93%|█████████████████████████  | 186/200 [00:31<00:02,  5.60epoch/s, loss=3.02, prev_loss=2.84]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  94%|█████████████████████████▏ | 187/200 [00:31<00:02,  5.80epoch/s, loss=3.07, prev_loss=3.02]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  94%|█████████████████████████▍ | 188/200 [00:31<00:02,  5.76epoch/s, loss=3.12, prev_loss=3.07]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  94%|█████████████████████████▌ | 189/200 [00:32<00:01,  5.95epoch/s, loss=3.03, prev_loss=3.12]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  95%|█████████████████████████▋ | 190/200 [00:32<00:01,  5.89epoch/s, loss=3.06, prev_loss=3.03]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  96%|█████████████████████████▊ | 191/200 [00:32<00:01,  6.08epoch/s, loss=2.87, prev_loss=3.06]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  96%|█████████████████████████▉ | 192/200 [00:32<00:01,  6.15epoch/s, loss=2.95, prev_loss=2.87]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  96%|██████████████████████████ | 193/200 [00:32<00:01,  6.16epoch/s, loss=3.11, prev_loss=2.95]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 115.48batch/s]\u001b[A\n",
      "Training epochs on cpu:  97%|██████████████████████████▏| 194/200 [00:32<00:01,  5.94epoch/s, loss=2.84, prev_loss=3.11]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  98%|██████████████████████████▎| 195/200 [00:33<00:00,  5.96epoch/s, loss=3.02, prev_loss=2.84]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|█████████████████████████████████████████████████▌    | 11/12 [00:00<00:00, 105.93batch/s]\u001b[A\n",
      "Training epochs on cpu:  98%|██████████████████████████▍| 196/200 [00:33<00:00,  5.69epoch/s, loss=2.82, prev_loss=3.02]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  98%|███████████████████████████▌| 197/200 [00:33<00:00,  5.80epoch/s, loss=2.8, prev_loss=2.82]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu:  99%|███████████████████████████▋| 198/200 [00:33<00:00,  5.89epoch/s, loss=2.95, prev_loss=2.8]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training epochs on cpu: 100%|██████████████████████████▊| 199/200 [00:33<00:00,  6.09epoch/s, loss=2.83, prev_loss=2.95]\u001b[A\n",
      "Training batches on cpu:   0%|                                                                | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|██████████████████████████████████████████████████████| 12/12 [00:00<00:00, 117.35batch/s]\u001b[A\n",
      "Training epochs on cpu: 100%|███████████████████████████| 200/200 [00:33<00:00,  5.90epoch/s, loss=2.96, prev_loss=2.83]\u001b[A\n",
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "WARNING:pykeen.utils:The filtered setting was enabled, but there were no `additional_filter_triples`\n",
      "given. This means you probably forgot to pass (at least) the training triples. Try:\n",
      "\n",
      "    additional_filter_triples=[dataset.training.mapped_triples]\n",
      "\n",
      "Or if you want to use the Bordes et al. (2013) approach to filtering, do:\n",
      "\n",
      "    additional_filter_triples=[\n",
      "        dataset.training.mapped_triples,\n",
      "        dataset.validation.mapped_triples,\n",
      "    ]\n",
      "\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "Evaluating on cpu: 100%|██████████████████████████████████████████████████████████| 159/159 [00:00<00:00, 2.03ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.08s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002304213121533394\n"
     ]
    }
   ],
   "source": [
    "from pykeen.models import ComplEx\n",
    "model = ComplEx(triples_factory=got_training)\n",
    "\n",
    "from pykeen.optimizers import Adam\n",
    "optimizer = Adam(params=model.get_grad_params())\n",
    "\n",
    "# from pykeen.regularizers import LP\n",
    "# regularizer = LP(p=3,weight=1e-5)\n",
    "\n",
    "from pykeen.training import SLCWATrainingLoop\n",
    "training_loop = SLCWATrainingLoop(model=model,\n",
    "                                  triples_factory=got_training,\n",
    "                                  optimizer=optimizer)\n",
    "\n",
    "#training\n",
    "_ = training_loop.train(triples_factory=got_training,\n",
    "                    num_epochs=200)\n",
    "\n",
    "#evaluating\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "evaluator = RankBasedEvaluator()\n",
    "mapped_triples = got_testing.mapped_triples\n",
    "\n",
    "results = evaluator.evaluate(\n",
    "            model=model,\n",
    "            mapped_triples=mapped_triples,\n",
    "            )\n",
    "\n",
    "print(results.get_metric('mrr'))\n",
    "\n",
    "#save results, this works also with the pipeline results, as the results object \n",
    "#returned by the evaluator is the same as the one returned from the pipeline\n",
    "save_dir = 'got_complex'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "results.to_df().to_csv(save_dir+os.path.sep+'results.csv')\n",
    "\n",
    "import torch\n",
    "torch.save(model,'trained_model.pkl')\n",
    "\n",
    "#to load the model use the following command\n",
    "# my_pykeen_model = torch.load('trained_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Try changing the parameters of your training process. See if you obtain a better model in terms of average loss. Save it as ./data/best_model.pkl. Which parameters work best for the dataset? \n",
    "\n",
    "Now use the training and test set you created in Exercise 2. Which loss you obtain, and for which parameters? \n",
    "\n",
    "Remember to save each model locally with a different name, so you can find them back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get some evaluation metrics for our model, they were already computed during evaluation time as part of the pipeline, and print them out.\n",
    "\n",
    "We are going to use the following evaluation metrics:\n",
    "- <i>mrr</i> (mean reciprocal rank) : this function computes the mean of the reciprocal of elements of a vector of rankings ranks\n",
    "- <i>hits_at_n</i> : this function computes how many elements of a vector of rankings ranks make it to the $top_n$ positions.\n",
    "\n",
    "NB : The choice of which _N_ makes more sense depends on the application and the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_result.get_metric('hits_at_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.0029\n",
      "\n",
      "Hits@10: 0.000000\n",
      "Interpretation: on average, the model guessed the correct subject or object 0.0% of the time when considering the top-10 better ranked triples.\n",
      "\n",
      "Hits@3: 0.000000\n",
      "Interpretation: on average, the model guessed the correct subject or object 0.0% of the time when considering the top-3 better ranked triples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = pipeline_result.get_metric('mrr')\n",
    "print(\"MRR: %.4f\" % (mrr))\n",
    "print()\n",
    "\n",
    "hits_10 = pipeline_result.get_metric('hits_at_10')\n",
    "print(\"Hits@10: %.6f\" % (hits_10))\n",
    "print(\"Interpretation: on average, the model guessed the correct subject or object %.1f%% of the time when considering the top-10 better ranked triples.\\n\" % (hits_10*100))\n",
    "\n",
    "hits_3 = pipeline_result.get_metric('hits_at_3')\n",
    "print(\"Hits@3: %.6f\" % (hits_3))\n",
    "print(\"Interpretation: on average, the model guessed the correct subject or object %.1f%% of the time when considering the top-3 better ranked triples.\\n\" % (hits_3*100))\n",
    "\n",
    "# hits_1 = hits_at_n_score(ranks, n=1)\n",
    "# print(\"Hits@1: %.2f\" % (hits_1))\n",
    "# print(\"Interpretation: on average, the model guessed the correct subject or object %.1f%% of the time when considering the top-1 better ranked triples.\\n\" % (hits_1*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Evaluate the models you created before (different set sizes, different parameters). Summarise your results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link prediction allows to infer missing links in a graph. This has many real-world use cases, such as predicting connections between people in a social network, interactions between proteins in a biological network, and music recommendation based on prior user taste.\n",
    "\n",
    "In our case, we are going to see which of the following candidate statements is more likely to be true. Note that the candidate statements below are made up, i.e. they are not in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen = np.array([\n",
    "    ['Jorah Mormont', 'SPOUSE', 'Daenerys Targaryen'],\n",
    "    ['Tyrion Lannister', 'SPOUSE', 'Missandei'],\n",
    "    [\"King's Landing\", 'SEAT_OF', 'House Lannister of Casterly Rock'],\n",
    "    ['Sansa Stark', 'SPOUSE', 'Petyr Baelish'],\n",
    "    ['Daenerys Targaryen', 'SPOUSE', 'Jon Snow'],\n",
    "    ['Daenerys Targaryen', 'SPOUSE', 'Craster'],\n",
    "    ['House Stark of Winterfell', 'IN_REGION', 'The North'],\n",
    "    ['House Stark of Winterfell', 'IN_REGION', 'Dorne'],\n",
    "    ['House Tyrell of Highgarden', 'IN_REGION', 'Beyond the Wall'],\n",
    "    ['Brandon Stark', 'ALLIED_WITH', 'House Stark of Winterfell'],\n",
    "    ['Brandon Stark', 'ALLIED_WITH', 'House Lannister of Casterly Rock'],    \n",
    "    ['Rhaegar Targaryen', 'PARENT_OF', 'Jon Snow'],\n",
    "    ['House Hutcheson', 'SWORN_TO', 'House Tyrell of Highgarden'],\n",
    "    ['Daenerys Targaryen', 'ALLIED_WITH', 'House Stark of Winterfell'],\n",
    "    ['Daenerys Targaryen', 'ALLIED_WITH', 'House Lannister of Casterly Rock'],\n",
    "    ['Jaime Lannister', 'PARENT_OF', 'Myrcella Baratheon'],\n",
    "    ['Robert I Baratheon', 'PARENT_OF', 'Myrcella Baratheon'],\n",
    "    ['Cersei Lannister', 'PARENT_OF', 'Myrcella Baratheon'],\n",
    "    ['Cersei Lannister', 'PARENT_OF', 'Brandon Stark'],\n",
    "    [\"Tywin Lannister\", 'PARENT_OF', 'Jaime Lannister'],\n",
    "    [\"Missandei\", 'SPOUSE', 'Grey Worm'],\n",
    "    [\"Brienne of Tarth\", 'SPOUSE', 'Jaime Lannister']\n",
    "])\n",
    "\n",
    "## we need to map the above triples to the id's which we used in our training/testing.\n",
    "## This information is stored in the triple factory \"got\", which we created at the beginning\n",
    "\n",
    "# unseen_filter = np.array(list({tuple(i) for i in np.vstack((positives_filter, X_unseen))}))\n",
    "#     filter_triples=unseen_filter,   # Corruption strategy filter defined above \n",
    "#     corrupt_side = 's+o',\n",
    "#     use_default_protocol=False, # corrupt subj and obj separately while evaluating\n",
    "#     verbose=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpykeen\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m predict_triples\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# got_unseen = triples.get_mapped_tripples(X_unseen,factory=got)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m pack = \u001b[43mpredict\u001b[49m.predict_triples(model=pipeline_result.model, triples=X_unseen, triples_factory=got)\n",
      "\u001b[31mNameError\u001b[39m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "#from pykeen import predict\n",
    "from pykeen.predict import predict_triples\n",
    "\n",
    "# got_unseen = triples.get_mapped_tripples(X_unseen,factory=got)\n",
    "pack = predict.predict_triples(model=pipeline_result.model, triples=X_unseen, triples_factory=got)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# scores are real numbers that need to be translated into probabilities [0,1] \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# for this, we use the expit transform.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expit\n\u001b[0;32m----> 5\u001b[0m processed_results \u001b[38;5;241m=\u001b[39m \u001b[43mpack\u001b[49m\u001b[38;5;241m.\u001b[39mprocess()\u001b[38;5;241m.\u001b[39mdf\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(processed_results)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m probs \u001b[38;5;241m=\u001b[39m expit(processed_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pack' is not defined"
     ]
    }
   ],
   "source": [
    "# scores are real numbers that need to be translated into probabilities [0,1] \n",
    "# for this, we use the expit transform.\n",
    "\n",
    "from scipy.special import expit\n",
    "processed_results = pack.process().df\n",
    "# print(processed_results)\n",
    "\n",
    "probs = expit(processed_results['score'])\n",
    "# print(probs)\n",
    "\n",
    "processed_results['prob'] = probs\n",
    "processed_results['triple'] = list(zip([' '.join(x) for x in X_unseen]))\n",
    "\n",
    "# processed_results\n",
    "pd.DataFrame(list(zip([' '.join(x) for x in X_unseen],  \n",
    "                      np.squeeze(processed_results['score']),\n",
    "                      np.squeeze(probs))), \n",
    "             columns=['statement', 'score', 'prob']).sort_values(\"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : the probabilities are not calibrated in any sense. To calibrate them, one may use a procedure such as [Platt scaling](https://en.wikipedia.org/wiki/Platt_scaling) or [Isotonic regression](https://en.wikipedia.org/wiki/Isotonic_regression). The challenge is to define what is a true triple and what is a false one, as the calibration of the probability of a triple being true depends on the base rate of positives and negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Analyse the results in the tables. Some predicted links are very likely to be true, others  capture things that never really happened. Can you spot which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Visualizing Embeddings\n",
    "\n",
    "It is possible to get an intuition on how the learned embedding are structured by plotting them into a 2-dimensional space. We can perform Principal Component Analysis on the entity embeddings, keeping 2 (or 3) principal components. ComplEx adds a further complication layer, as it uses complex vectors, which are in a sense already 2-dimensional. To tackle this, we will simply apply a Real-Valued Transformation by stacking the real and imaginary part of the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.utils:using automatically assigned random_state=1022919809\n",
      "INFO:pykeen.triples.splitting:done splitting triples to groups of sizes [399, 604]\n",
      "[I 2025-03-04 21:31:38,623] A new study created in memory with name: no-name-ca81141d-6b82-4c04-b7cb-a71a19db1508\n",
      "INFO:pykeen.hpo.hpo:Using model: <class 'pykeen.models.unimodal.complex.ComplEx'>\n",
      "INFO:pykeen.hpo.hpo:Using loss: <class 'pykeen.losses.SoftplusLoss'>\n",
      "INFO:pykeen.hpo.hpo:Using regularizer: <class 'pykeen.regularizers.LpRegularizer'>\n",
      "INFO:pykeen.hpo.hpo:Using optimizer: <class 'torch.optim.adam.Adam'>\n",
      "INFO:pykeen.hpo.hpo:Using training loop: <class 'pykeen.training.slcwa.SLCWATrainingLoop'>\n",
      "INFO:pykeen.hpo.hpo:Using negative sampler: <class 'pykeen.sampling.basic_negative_sampler.BasicNegativeSampler'>\n",
      "INFO:pykeen.hpo.hpo:Using evaluator: <class 'pykeen.evaluation.rank_based_evaluator.RankBasedEvaluator'>\n",
      "INFO:pykeen.hpo.hpo:Attempting to maximize both.realistic.inverse_harmonic_mean_rank\n",
      "INFO:pykeen.hpo.hpo:Filter validation triples when testing: True\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 79756552.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 100/100 [00:15<00:00,  6.57epoch/s, loss=0.00963, prev_loss=0.00976]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.09ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.56s seconds\n",
      "[I 2025-03-04 21:31:54,698] Trial 0 finished with value: 0.038534484803676605 and parameters: {'model.embedding_dim': 176, 'optimizer.lr': 0.05521591898865549, 'training.num_epochs': 100}. Best is trial 0 with value: 0.038534484803676605.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1631388700.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:47<00:00,  6.34epoch/s, loss=0.00183, prev_loss=0.00188]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 890triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.68s seconds\n",
      "[I 2025-03-04 21:32:42,952] Trial 1 finished with value: 0.07746691256761551 and parameters: {'model.embedding_dim': 208, 'optimizer.lr': 0.04369275746752547, 'training.num_epochs': 300}. Best is trial 1 with value: 0.07746691256761551.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 584739536.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 100/100 [00:13<00:00,  7.61epoch/s, loss=0.00812, prev_loss=0.00779]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.35s seconds\n",
      "[I 2025-03-04 21:32:56,619] Trial 2 finished with value: 0.09395498037338257 and parameters: {'model.embedding_dim': 96, 'optimizer.lr': 0.061756458656931905, 'training.num_epochs': 100}. Best is trial 2 with value: 0.09395498037338257.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1342452825.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:51<00:00,  8.08epoch/s, loss=0.000618, prev_loss=0.000742]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.56ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-04 21:34:48,429] Trial 3 finished with value: 0.14083725214004517 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.038866041797367225, 'training.num_epochs': 900}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 293107506.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:37<00:00,  8.00epoch/s, loss=0.00109, prev_loss=0.00107]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-04 21:35:26,329] Trial 4 finished with value: 0.13664847612380981 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.06735180265186048, 'training.num_epochs': 300}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 550349517.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 100/100 [00:13<00:00,  7.52epoch/s, loss=0.00508, prev_loss=0.00602]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.38s seconds\n",
      "[I 2025-03-04 21:35:40,261] Trial 5 finished with value: 0.08363202214241028 and parameters: {'model.embedding_dim': 96, 'optimizer.lr': 0.07290379821032442, 'training.num_epochs': 100}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 855926335.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:26<00:00,  7.51epoch/s, loss=0.0722, prev_loss=0.0749]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.66ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.37s seconds\n",
      "[I 2025-03-04 21:36:07,497] Trial 6 finished with value: 0.017888663336634636 and parameters: {'model.embedding_dim': 96, 'optimizer.lr': 0.020528114655733273, 'training.num_epochs': 200}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 447052847.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:50<00:00,  5.89epoch/s, loss=0.00136, prev_loss=0.00147]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 623triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.98s seconds\n",
      "[I 2025-03-04 21:36:59,684] Trial 7 finished with value: 0.07019493728876114 and parameters: {'model.embedding_dim': 256, 'optimizer.lr': 0.06201073264977663, 'training.num_epochs': 300}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1395214554.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:21<00:00,  7.34epoch/s, loss=0.000708, prev_loss=0.000715]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.38s seconds\n",
      "[I 2025-03-04 21:38:21,991] Trial 8 finished with value: 0.12487807869911194 and parameters: {'model.embedding_dim': 96, 'optimizer.lr': 0.08561601186522376, 'training.num_epochs': 600}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 578733452.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 100/100 [00:13<00:00,  7.20epoch/s, loss=0.098, prev_loss=0.0959]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.47ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.42s seconds\n",
      "[I 2025-03-04 21:38:36,502] Trial 9 finished with value: 0.01429920457303524 and parameters: {'model.embedding_dim': 112, 'optimizer.lr': 0.03964703078213321, 'training.num_epochs': 100}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 749833718.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [01:58<00:00,  8.45epoch/s, loss=0.218, prev_loss=0.215]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 6.12ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.10s seconds\n",
      "[I 2025-03-04 21:40:35,052] Trial 10 finished with value: 0.010990097187459469 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0037124089779136393, 'training.num_epochs': 1000}. Best is trial 3 with value: 0.14083725214004517.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 782602538.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:00<00:00,  8.31epoch/s, loss=0.000641, prev_loss=0.000768]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.70ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "[I 2025-03-04 21:42:35,735] Trial 11 finished with value: 0.1425037980079651 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.031129823075335343, 'training.num_epochs': 1000}. Best is trial 11 with value: 0.1425037980079651.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1776376461.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [01:58<00:00,  8.41epoch/s, loss=0.000732, prev_loss=0.00106]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 6.08ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "[I 2025-03-04 21:44:34,908] Trial 12 finished with value: 0.1640172302722931 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.027158521838718846, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 827383511.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:35<00:00,  8.34epoch/s, loss=0.00142, prev_loss=0.00138]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "[I 2025-03-04 21:46:11,130] Trial 13 finished with value: 0.15654659271240234 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02072972826473751, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 832799021.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:45<00:00,  7.61epoch/s, loss=0.00244, prev_loss=0.00297]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.17ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.29s seconds\n",
      "[I 2025-03-04 21:47:56,760] Trial 14 finished with value: 0.0851757749915123 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.014905080344955511, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 547886403.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:46<00:00,  6.60epoch/s, loss=0.0014, prev_loss=0.00122] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.07ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.57s seconds\n",
      "[I 2025-03-04 21:49:43,601] Trial 15 finished with value: 0.10955269634723663 and parameters: {'model.embedding_dim': 144, 'optimizer.lr': 0.02455377845568862, 'training.num_epochs': 700}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 101989616.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:49<00:00,  7.31epoch/s, loss=0.0712, prev_loss=0.0742]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-04 21:51:33,468] Trial 16 finished with value: 0.02253379486501217 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.004501110528962578, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 540927289.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:01<00:00,  8.18epoch/s, loss=0.0216, prev_loss=0.0212]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 8.10ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.08s seconds\n",
      "[I 2025-03-04 21:52:34,843] Trial 17 finished with value: 0.09599447250366211 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.012376917997032388, 'training.num_epochs': 500}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 764879085.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:59<00:00,  7.54epoch/s, loss=0.000684, prev_loss=0.000995]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-04 21:54:34,627] Trial 18 finished with value: 0.11935856938362122 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.03082247007971448, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 710504830.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:14<00:00,  6.68epoch/s, loss=0.000976, prev_loss=0.00103] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.17ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.52s seconds\n",
      "[I 2025-03-04 21:55:50,174] Trial 19 finished with value: 0.12133161723613739 and parameters: {'model.embedding_dim': 144, 'optimizer.lr': 0.051099852690589115, 'training.num_epochs': 500}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1312650734.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:50<00:00,  6.35epoch/s, loss=0.000981, prev_loss=0.000872]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 995triple/s]  \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.61s seconds\n",
      "[I 2025-03-04 21:57:41,272] Trial 20 finished with value: 0.08379454910755157 and parameters: {'model.embedding_dim': 176, 'optimizer.lr': 0.0951244265800864, 'training.num_epochs': 700}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 640201302.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:00<00:00,  8.30epoch/s, loss=0.000792, prev_loss=0.000721]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.09ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "[I 2025-03-04 21:59:42,178] Trial 21 finished with value: 0.1543891876935959 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.032877028523541366, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1839914261.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:05<00:00,  8.00epoch/s, loss=0.000676, prev_loss=0.000617]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.11ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-04 22:01:47,580] Trial 22 finished with value: 0.15521222352981567 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02996980192042673, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 42531660.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:53<00:00,  7.92epoch/s, loss=0.000944, prev_loss=0.000869]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.09ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-04 22:03:41,596] Trial 23 finished with value: 0.13903188705444336 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.022811303601416866, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1993607513.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:47<00:00,  7.43epoch/s, loss=0.00226, prev_loss=0.00301]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-04 22:05:29,723] Trial 24 finished with value: 0.11416177451610565 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.012881770896846721, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1111806556.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:05<00:00,  7.94epoch/s, loss=0.000532, prev_loss=0.000952]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.41ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-04 22:07:36,031] Trial 25 finished with value: 0.12539148330688477 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04402264589953647, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 187845282.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:53<00:00,  7.90epoch/s, loss=0.000722, prev_loss=0.000764]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.97ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-04 22:09:30,352] Trial 26 finished with value: 0.13889043033123016 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.028437795405503345, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 91009030.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:38<00:00,  7.08epoch/s, loss=0.00168, prev_loss=0.00182]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.74ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.35s seconds\n",
      "[I 2025-03-04 22:11:09,775] Trial 27 finished with value: 0.12350697815418243 and parameters: {'model.embedding_dim': 80, 'optimizer.lr': 0.01833231274714585, 'training.num_epochs': 700}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1440289373.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [02:08<00:00,  6.22epoch/s, loss=0.000954, prev_loss=0.00101] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.25ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.49s seconds\n",
      "[I 2025-03-04 22:13:19,081] Trial 28 finished with value: 0.09130608290433884 and parameters: {'model.embedding_dim': 128, 'optimizer.lr': 0.03462760052801773, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2129121144.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:28<00:00,  6.08epoch/s, loss=0.00372, prev_loss=0.00308]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 929triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.66s seconds\n",
      "[I 2025-03-04 22:15:48,063] Trial 29 finished with value: 0.03128098323941231 and parameters: {'model.embedding_dim': 192, 'optimizer.lr': 0.009776406339488376, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1672810441.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:16<00:00,  7.85epoch/s, loss=0.000695, prev_loss=0.000627]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.07ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-04 22:17:04,892] Trial 30 finished with value: 0.15113042294979095 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04983322668757029, 'training.num_epochs': 600}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 727931664.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:01<00:00,  8.21epoch/s, loss=0.00128, prev_loss=0.000739]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 6.33ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.10s seconds\n",
      "[I 2025-03-04 22:19:06,917] Trial 31 finished with value: 0.15443776547908783 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.024902961781802267, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1178408925.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:12<00:00,  7.56epoch/s, loss=0.000836, prev_loss=0.000743]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.16ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.29s seconds\n",
      "[I 2025-03-04 22:21:19,597] Trial 32 finished with value: 0.14695097506046295 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.025015124848998902, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1926846349.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:05<00:00,  7.96epoch/s, loss=0.000529, prev_loss=0.000635]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.64ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-04 22:23:25,563] Trial 33 finished with value: 0.1515345722436905 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04545213549603935, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1381402369.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:45<00:00,  5.43epoch/s, loss=0.0015, prev_loss=0.00185] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:01<00:00, 540triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 1.13s seconds\n",
      "[I 2025-03-04 22:26:12,650] Trial 34 finished with value: 0.0351809561252594 and parameters: {'model.embedding_dim': 256, 'optimizer.lr': 0.01663811113741192, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 639187225.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:04<00:00,  7.24epoch/s, loss=0.000673, prev_loss=0.000626]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.93ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-04 22:28:17,496] Trial 35 finished with value: 0.1330992728471756 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.03832832936581872, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 21370697.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:24<00:00,  6.92epoch/s, loss=0.00394, prev_loss=0.00395]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.49ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.41s seconds\n",
      "[I 2025-03-04 22:30:42,660] Trial 36 finished with value: 0.08142058551311493 and parameters: {'model.embedding_dim': 80, 'optimizer.lr': 0.007859592664522744, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 675997607.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [07:32<00:00,  1.77epoch/s, loss=1.41, prev_loss=1.4]    \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.20ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-04 22:38:15,774] Trial 37 finished with value: 0.003194522112607956 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.0011235956229300702, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1257956978.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:05<00:00,  6.07epoch/s, loss=0.00353, prev_loss=0.00307]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 801triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.76s seconds\n",
      "[I 2025-03-04 22:39:22,716] Trial 38 finished with value: 0.05369987711310387 and parameters: {'model.embedding_dim': 224, 'optimizer.lr': 0.027268652626584455, 'training.num_epochs': 400}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1244673912.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:06<00:00,  7.13epoch/s, loss=0.00109, prev_loss=0.00109]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.38s seconds\n",
      "[I 2025-03-04 22:41:29,551] Trial 39 finished with value: 0.11942662298679352 and parameters: {'model.embedding_dim': 80, 'optimizer.lr': 0.020669412535172637, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 38586295.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:35<00:00,  7.30epoch/s, loss=0.000669, prev_loss=0.000766]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.90ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-04 22:43:05,915] Trial 40 finished with value: 0.13725721836090088 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.056913353543152065, 'training.num_epochs': 700}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1199786706.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:03<00:00,  8.08epoch/s, loss=0.000616, prev_loss=0.000597]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.49ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-04 22:45:09,955] Trial 41 finished with value: 0.1511356085538864 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0337803179564505, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1212015060.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:08<00:00,  7.76epoch/s, loss=0.00058, prev_loss=0.000692]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-04 22:47:19,128] Trial 42 finished with value: 0.13142579793930054 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03994873157922665, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 913276750.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:16<00:00,  7.32epoch/s, loss=0.000637, prev_loss=0.000697]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-04 22:49:36,077] Trial 43 finished with value: 0.13347163796424866 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03417353590309788, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 161941525.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:06<00:00,  7.10epoch/s, loss=0.000891, prev_loss=0.00119]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.02ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-04 22:51:43,385] Trial 44 finished with value: 0.13487619161605835 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.02038743125216917, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 809266250.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:07<00:00,  7.86epoch/s, loss=0.000765, prev_loss=0.000986]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.76ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-04 22:53:50,872] Trial 45 finished with value: 0.12921370565891266 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02767232441347439, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 256488342.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:53<00:00,  7.05epoch/s, loss=0.000732, prev_loss=0.000777]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.99ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-04 22:55:44,861] Trial 46 finished with value: 0.14254900813102722 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.03719059913542347, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 735668776.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:13<00:00,  7.46epoch/s, loss=0.000632, prev_loss=0.000641]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.12ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-04 22:57:59,190] Trial 47 finished with value: 0.12134215235710144 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03078990940729632, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 920860814.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:51<00:00,  8.04epoch/s, loss=0.00144, prev_loss=0.0013]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.36ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "[I 2025-03-04 22:59:51,455] Trial 48 finished with value: 0.13200809061527252 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.023387575369013525, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2048809290.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:03<00:00,  8.12epoch/s, loss=0.000569, prev_loss=0.000653]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.16ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "[I 2025-03-04 23:01:54,908] Trial 49 finished with value: 0.14342419803142548 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.06830935164012887, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1750581289.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:29<00:00,  6.85epoch/s, loss=0.00294, prev_loss=0.00355]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.44ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.43s seconds\n",
      "[I 2025-03-04 23:02:24,759] Trial 50 finished with value: 0.09443439543247223 and parameters: {'model.embedding_dim': 112, 'optimizer.lr': 0.047615553764058835, 'training.num_epochs': 200}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 597833385.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:04<00:00,  8.04epoch/s, loss=0.000483, prev_loss=0.000518]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.57ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-04 23:04:29,418] Trial 51 finished with value: 0.14067673683166504 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.045851629118704246, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1418054432.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:57<00:00,  7.68epoch/s, loss=0.000642, prev_loss=0.000551]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.96ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-04 23:06:27,000] Trial 52 finished with value: 0.14626577496528625 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04182499591362976, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 166054511.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:15<00:00,  7.38epoch/s, loss=0.000555, prev_loss=0.000542]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-04 23:08:42,945] Trial 53 finished with value: 0.1262398362159729 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.05488942284664913, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1649404131.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:40<00:00,  7.94epoch/s, loss=0.00115, prev_loss=0.000807] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.39ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-04 23:10:23,962] Trial 54 finished with value: 0.13884246349334717 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03451714432305985, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 189560359.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:00<00:00,  7.46epoch/s, loss=0.000669, prev_loss=0.00066] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-04 23:12:25,009] Trial 55 finished with value: 0.11534436047077179 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.030020007603747994, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1411852981.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:20<00:00,  7.13epoch/s, loss=0.00139, prev_loss=0.00131]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.84ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.34s seconds\n",
      "[I 2025-03-04 23:14:45,748] Trial 56 finished with value: 0.13487382233142853 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.015238272406650861, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 646734133.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:06<00:00,  7.91epoch/s, loss=0.00103, prev_loss=0.00139] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.99ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "[I 2025-03-04 23:16:52,497] Trial 57 finished with value: 0.11793611198663712 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.08301033955478246, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1289107365.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:36<00:00,  6.20epoch/s, loss=0.0011, prev_loss=0.000986]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.03ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.59s seconds\n",
      "[I 2025-03-04 23:18:30,041] Trial 58 finished with value: 0.11081768572330475 and parameters: {'model.embedding_dim': 160, 'optimizer.lr': 0.04221165352937197, 'training.num_epochs': 600}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 630920161.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:58<00:00,  7.61epoch/s, loss=0.000791, prev_loss=0.000837]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.95ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-04 23:20:28,730] Trial 59 finished with value: 0.13995514810085297 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.025244593424871477, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1276055535.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:03<00:00,  7.29epoch/s, loss=0.00114, prev_loss=0.000986]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.29ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-04 23:22:32,536] Trial 60 finished with value: 0.128505676984787 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.018044165435254878, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1315644088.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:06<00:00,  7.93epoch/s, loss=0.000695, prev_loss=0.000668]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 7.39ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.09s seconds\n",
      "[I 2025-03-04 23:24:38,835] Trial 61 finished with value: 0.1444510668516159 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03338890373160472, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1755702964.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:07<00:00,  7.84epoch/s, loss=0.000621, prev_loss=0.000613]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.14ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "[I 2025-03-04 23:26:46,699] Trial 62 finished with value: 0.1512143611907959 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03553095139549782, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 541681099.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:19<00:00,  7.17epoch/s, loss=0.000589, prev_loss=0.000841]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.76ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-04 23:29:06,644] Trial 63 finished with value: 0.143504798412323 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.037205595999952795, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1657286509.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:57<00:00,  7.63epoch/s, loss=0.000745, prev_loss=0.00105] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.37ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-04 23:31:04,863] Trial 64 finished with value: 0.15379437804222107 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.027907283619480975, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 247687081.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:01<00:00,  7.39epoch/s, loss=0.00081, prev_loss=0.000831] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.82ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-04 23:33:06,997] Trial 65 finished with value: 0.13047176599502563 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02153095051995993, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2104078844.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:51<00:00,  7.15epoch/s, loss=0.00353, prev_loss=0.00343]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.22ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.28s seconds\n",
      "[I 2025-03-04 23:34:59,402] Trial 66 finished with value: 0.11544741690158844 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.011461288367646733, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 821779691.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:56<00:00,  7.70epoch/s, loss=0.000712, prev_loss=0.00113] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.92ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "[I 2025-03-04 23:36:56,524] Trial 67 finished with value: 0.1336197555065155 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.029186761623226355, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1902066470.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.87epoch/s, loss=0.00113, prev_loss=0.00115] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.91ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-04 23:39:22,513] Trial 68 finished with value: 0.12978464365005493 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.023659563407702935, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1971486288.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:51<00:00,  7.16epoch/s, loss=0.00117, prev_loss=0.000963] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.96ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-04 23:41:14,541] Trial 69 finished with value: 0.14184436202049255 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02681661539263224, 'training.num_epochs': 800}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 966410389.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:56<00:00,  7.75epoch/s, loss=0.012, prev_loss=0.0114] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.29ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "[I 2025-03-04 23:43:11,011] Trial 70 finished with value: 0.08713329583406448 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.007469912155371773, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1298450968.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:09<00:00,  7.74epoch/s, loss=0.000968, prev_loss=0.000832]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.24ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "[I 2025-03-04 23:45:20,527] Trial 71 finished with value: 0.14026406407356262 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03201274652927713, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 61981499.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:10<00:00,  7.68epoch/s, loss=0.000751, prev_loss=0.000615]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.67ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-04 23:47:31,092] Trial 72 finished with value: 0.1299254596233368 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.036713215085780224, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 159069508.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:16<00:00,  7.34epoch/s, loss=0.000957, prev_loss=0.000908]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.86ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-04 23:49:47,639] Trial 73 finished with value: 0.13104677200317383 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.019207656664294893, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 991921192.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:03<00:00,  7.31epoch/s, loss=0.000597, prev_loss=0.000574]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.04ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-04 23:51:51,040] Trial 74 finished with value: 0.13572151958942413 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.040108312191221664, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1644464769.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:10<00:00,  7.68epoch/s, loss=0.000927, prev_loss=0.000734]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.79ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "[I 2025-03-04 23:54:01,484] Trial 75 finished with value: 0.14301498234272003 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02541456574509796, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1071324846.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:21<00:00,  7.08epoch/s, loss=0.000719, prev_loss=0.00059]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.16ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.29s seconds\n",
      "[I 2025-03-04 23:56:23,268] Trial 76 finished with value: 0.11743739992380142 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.050507150201740986, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 87566888.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:03<00:00,  7.28epoch/s, loss=0.00179, prev_loss=0.0019] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.66ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-04 23:58:27,216] Trial 77 finished with value: 0.1079101711511612 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.014239017301851124, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1345676331.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:10<00:00,  7.67epoch/s, loss=0.000758, prev_loss=0.000917]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 00:00:37,902] Trial 78 finished with value: 0.1241324245929718 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.029108638423612027, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1433833171.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:29<00:00,  5.59epoch/s, loss=0.00203, prev_loss=0.00168]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 784triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.78s seconds\n",
      "[I 2025-03-05 00:02:08,347] Trial 79 finished with value: 0.058218762278556824 and parameters: {'model.embedding_dim': 208, 'optimizer.lr': 0.03183034693636465, 'training.num_epochs': 500}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1026381622.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [01:56<00:00,  7.74epoch/s, loss=0.000605, prev_loss=0.000693]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.51ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-05 00:04:04,913] Trial 80 finished with value: 0.13384301960468292 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05388031825219171, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2111077338.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:14<00:00,  7.42epoch/s, loss=0.000507, prev_loss=0.000509]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.41ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 00:06:20,085] Trial 81 finished with value: 0.1445569396018982 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.044498230912800876, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 496954451.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:31<00:00,  6.61epoch/s, loss=0.000563, prev_loss=0.000609]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.28ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 00:08:51,854] Trial 82 finished with value: 0.14140108227729797 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.034378927254039654, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 105575573.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:16<00:00,  7.32epoch/s, loss=0.000808, prev_loss=0.000573]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.76ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "[I 2025-03-05 00:11:08,827] Trial 83 finished with value: 0.15304386615753174 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03636109653576988, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 558536273.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:27<00:00,  6.79epoch/s, loss=0.000672, prev_loss=0.000655]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.03ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 00:13:36,516] Trial 84 finished with value: 0.13750059902668 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.04152584186383492, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 852778381.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:03<00:00,  7.31epoch/s, loss=0.00066, prev_loss=0.000834] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 00:15:39,978] Trial 85 finished with value: 0.1490853875875473 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.035823994035912334, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1073535668.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:39<00:00,  7.02epoch/s, loss=0.000673, prev_loss=0.000659]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.38ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 00:17:20,059] Trial 86 finished with value: 0.13522526621818542 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04807356459813675, 'training.num_epochs': 700}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 236509152.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:16<00:00,  7.35epoch/s, loss=0.00111, prev_loss=0.00102] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.63ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 00:19:36,556] Trial 87 finished with value: 0.14258572459220886 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.022469662028683685, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1879630091.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:59<00:00,  6.73epoch/s, loss=0.00256, prev_loss=0.00288]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.98ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 00:20:36,504] Trial 88 finished with value: 0.12786953151226044 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.026305071002495517, 'training.num_epochs': 400}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 834894724.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:19<00:00,  7.18epoch/s, loss=0.000593, prev_loss=0.000589]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.72ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 00:22:56,209] Trial 89 finished with value: 0.13620086014270782 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03802932852673428, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1026381913.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:10<00:00,  6.91epoch/s, loss=0.00091, prev_loss=0.00072]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.47ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 00:25:06,920] Trial 90 finished with value: 0.12979111075401306 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03153309354658216, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 550586177.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:18<00:00,  7.23epoch/s, loss=0.00137, prev_loss=0.000975]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.73ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 00:27:25,545] Trial 91 finished with value: 0.14359816908836365 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02832749368378345, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 887935757.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:28<00:00,  6.74epoch/s, loss=0.000604, prev_loss=0.000862]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.54ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 00:29:54,378] Trial 92 finished with value: 0.13574418425559998 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.033059323081111196, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1383878188.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:18<00:00,  7.21epoch/s, loss=0.000691, prev_loss=0.000513]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.47ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 00:32:13,411] Trial 93 finished with value: 0.1261059194803238 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.045048753128881035, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1331838250.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:45<00:00,  6.03epoch/s, loss=0.000766, prev_loss=0.000745]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.13ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.54s seconds\n",
      "[I 2025-03-05 00:35:00,123] Trial 94 finished with value: 0.10692457854747772 and parameters: {'model.embedding_dim': 112, 'optimizer.lr': 0.03964329347311551, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 604371502.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:04<00:00,  7.20epoch/s, loss=0.000596, prev_loss=0.0012]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 00:37:05,398] Trial 95 finished with value: 0.15047135949134827 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03582131101365082, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 685476056.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:50<00:00,  5.87epoch/s, loss=0.00106, prev_loss=0.000849]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.61s seconds\n",
      "[I 2025-03-05 00:39:56,571] Trial 96 finished with value: 0.11493314802646637 and parameters: {'model.embedding_dim': 128, 'optimizer.lr': 0.03010479566717288, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 548587288.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.84epoch/s, loss=0.00118, prev_loss=0.000974]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 00:42:23,182] Trial 97 finished with value: 0.1316801905632019 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.017207669621589032, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 160048745.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:11<00:00,  6.86epoch/s, loss=0.00122, prev_loss=0.000834] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.55ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 00:44:34,874] Trial 98 finished with value: 0.13983632624149323 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.021371225258308035, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2041558323.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:04<00:00,  7.21epoch/s, loss=0.00109, prev_loss=0.000884] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.51ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 00:46:39,983] Trial 99 finished with value: 0.14594316482543945 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.027688473083013074, 'training.num_epochs': 900}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 256967089.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:30<00:00,  6.65epoch/s, loss=0.000679, prev_loss=0.000584]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.88ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 00:49:10,964] Trial 100 finished with value: 0.13734734058380127 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.05808140356517805, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1414559926.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:23<00:00,  7.15epoch/s, loss=0.000811, prev_loss=0.000752]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.67ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 00:50:35,279] Trial 101 finished with value: 0.14236457645893097 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05207151122166111, 'training.num_epochs': 600}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1978233952.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:42<00:00,  6.81epoch/s, loss=0.00123, prev_loss=0.00126]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.53ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 00:52:18,551] Trial 102 finished with value: 0.14510175585746765 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.024266583709002264, 'training.num_epochs': 700}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1331414119.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:19<00:00,  7.17epoch/s, loss=0.000745, prev_loss=0.000514]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.92ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "[I 2025-03-05 00:54:38,363] Trial 103 finished with value: 0.1290968805551529 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04872863753063085, 'training.num_epochs': 1000}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 212825589.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:59<00:00,  6.78epoch/s, loss=0.00157, prev_loss=0.00112]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 00:55:37,778] Trial 104 finished with value: 0.1589042842388153 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.0426950142512036, 'training.num_epochs': 400}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 368662673.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:46<00:00,  6.48epoch/s, loss=0.00193, prev_loss=0.00209]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 00:56:24,563] Trial 105 finished with value: 0.14096176624298096 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04253929173045068, 'training.num_epochs': 300}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1003247818.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:42<00:00,  7.08epoch/s, loss=0.0031, prev_loss=0.00276] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 00:57:07,303] Trial 106 finished with value: 0.10522028058767319 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04577081430021109, 'training.num_epochs': 300}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1526434740.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 100/100 [00:15<00:00,  6.45epoch/s, loss=0.119, prev_loss=0.125]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.08ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.30s seconds\n",
      "[I 2025-03-05 00:57:23,294] Trial 107 finished with value: 0.022636381909251213 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.03853453178137932, 'training.num_epochs': 100}. Best is trial 12 with value: 0.1640172302722931.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 313606983.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:56<00:00,  7.04epoch/s, loss=0.0031, prev_loss=0.00335] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.23ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "[I 2025-03-05 00:58:20,365] Trial 108 finished with value: 0.17843475937843323 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03340488281216353, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1422129022.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:59<00:00,  6.69epoch/s, loss=0.00707, prev_loss=0.00641]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.43ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 00:59:20,538] Trial 109 finished with value: 0.124366395175457 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.019234392994079686, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1232954005.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:56<00:00,  7.06epoch/s, loss=0.00311, prev_loss=0.00268]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.35ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:00:17,569] Trial 110 finished with value: 0.14442746341228485 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03518876449048632, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 140395389.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:10<00:00,  7.05epoch/s, loss=0.00208, prev_loss=0.00163]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.27ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "[I 2025-03-05 01:01:28,790] Trial 111 finished with value: 0.13856610655784607 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.032541431026881895, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 452074459.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:22<00:00,  4.85epoch/s, loss=0.00236, prev_loss=0.00241]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 642triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.95s seconds\n",
      "[I 2025-03-05 01:02:52,472] Trial 112 finished with value: 0.0558650903403759 and parameters: {'model.embedding_dim': 240, 'optimizer.lr': 0.030499857528159896, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1777764701.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:42<00:00,  6.98epoch/s, loss=0.00263, prev_loss=0.00292]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 01:03:35,872] Trial 113 finished with value: 0.16582569479942322 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04019270363120965, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1500443627.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:42<00:00,  7.08epoch/s, loss=0.00339, prev_loss=0.00351]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.56ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 01:04:18,603] Trial 114 finished with value: 0.14443200826644897 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0398753793268148, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1835694247.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:29<00:00,  6.69epoch/s, loss=0.00496, prev_loss=0.00604]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.50ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 01:04:48,912] Trial 115 finished with value: 0.12306152284145355 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04321402964153712, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 426381371.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:42<00:00,  7.02epoch/s, loss=0.00252, prev_loss=0.00173]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.73ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 01:05:31,968] Trial 116 finished with value: 0.14717015624046326 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.046805938284836576, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 821408034.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:29<00:00,  6.74epoch/s, loss=0.0072, prev_loss=0.00723] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.37ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 01:06:02,128] Trial 117 finished with value: 0.10829557478427887 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03732057910147132, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 470233894.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:56<00:00,  7.05epoch/s, loss=0.00428, prev_loss=0.00576]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.17ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 01:06:59,206] Trial 118 finished with value: 0.13069215416908264 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.025912103944317012, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 39355559.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:14<00:00,  6.67epoch/s, loss=0.00224, prev_loss=0.00293]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.99ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 01:08:14,639] Trial 119 finished with value: 0.12992694973945618 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.023586452426016494, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 983512617.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:13<00:00,  5.41epoch/s, loss=0.00139, prev_loss=0.00163]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 846triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.72s seconds\n",
      "[I 2025-03-05 01:09:29,582] Trial 120 finished with value: 0.10458533465862274 and parameters: {'model.embedding_dim': 160, 'optimizer.lr': 0.04167328009870809, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1922040169.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:22<00:00,  7.02epoch/s, loss=0.000632, prev_loss=0.000667]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 01:11:52,440] Trial 121 finished with value: 0.15229637920856476 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.033747273592365366, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1480697308.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:21<00:00,  7.05epoch/s, loss=0.0012, prev_loss=0.000855] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.08ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "[I 2025-03-05 01:14:14,591] Trial 122 finished with value: 0.1401921510696411 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02850274402759695, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1737297075.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:42<00:00,  7.02epoch/s, loss=0.00432, prev_loss=0.00479]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 6.13ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "[I 2025-03-05 01:14:57,574] Trial 123 finished with value: 0.15570753812789917 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03336298279036177, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1962156081.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:45<00:00,  6.57epoch/s, loss=0.00358, prev_loss=0.00324]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.56ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 01:15:43,638] Trial 124 finished with value: 0.1470842957496643 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.032838261059802296, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1113235150.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:43<00:00,  6.97epoch/s, loss=0.00906, prev_loss=0.00745]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.36ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:16:27,002] Trial 125 finished with value: 0.13601897656917572 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02971489019063006, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1201625512.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:28<00:00,  6.99epoch/s, loss=0.0178, prev_loss=0.0166]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.49ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 01:16:55,941] Trial 126 finished with value: 0.11354224383831024 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03367314153286024, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1464565815.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:45<00:00,  6.64epoch/s, loss=0.00618, prev_loss=0.00586]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.02ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 01:17:41,618] Trial 127 finished with value: 0.11149408668279648 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.026571494769857228, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 549005292.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:54<00:00,  7.01epoch/s, loss=0.000639, prev_loss=0.00083] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.59ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 01:19:36,065] Trial 128 finished with value: 0.13004028797149658 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04031050409681098, 'training.num_epochs': 800}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2121054615.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:49<00:00,  6.01epoch/s, loss=0.00302, prev_loss=0.00251]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.11ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.55s seconds\n",
      "[I 2025-03-05 01:20:26,757] Trial 129 finished with value: 0.11408950388431549 and parameters: {'model.embedding_dim': 96, 'optimizer.lr': 0.03809465427300786, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2078195979.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:26<00:00,  6.97epoch/s, loss=0.00204, prev_loss=0.000921] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.68ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 01:21:53,118] Trial 130 finished with value: 0.13431711494922638 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.09225233311163861, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 502728642.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:23<00:00,  6.97epoch/s, loss=0.000613, prev_loss=0.000664]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.55ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-05 01:24:16,809] Trial 131 finished with value: 0.14758335053920746 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03672304865333849, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1166345190.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:31<00:00,  6.58epoch/s, loss=0.000626, prev_loss=0.000629]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.90ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 01:26:49,175] Trial 132 finished with value: 0.13473938405513763 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.031312810835813255, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1572652715.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.89epoch/s, loss=0.000588, prev_loss=0.000556]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 01:29:14,700] Trial 133 finished with value: 0.1370457261800766 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.034810228987944725, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1850008887.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:28<00:00,  6.95epoch/s, loss=0.00684, prev_loss=0.00772]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.26ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:29:43,823] Trial 134 finished with value: 0.1443311721086502 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.043695508858075646, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1993893556.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:31<00:00,  6.59epoch/s, loss=0.00058, prev_loss=0.000604]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.00ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 01:32:15,979] Trial 135 finished with value: 0.1559879034757614 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03624290201283781, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 944594535.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:32<00:00,  6.57epoch/s, loss=0.000719, prev_loss=0.000749]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.28ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 01:34:48,660] Trial 136 finished with value: 0.15134896337985992 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02834999123143831, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1600911605.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:24<00:00,  6.24epoch/s, loss=0.00109, prev_loss=0.000755] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.48ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.42s seconds\n",
      "[I 2025-03-05 01:37:13,454] Trial 137 finished with value: 0.14799001812934875 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.030955450820676668, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 907594824.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.52epoch/s, loss=0.000908, prev_loss=0.00075]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.90ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 01:39:47,336] Trial 138 finished with value: 0.13983254134655 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.022402978742283943, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1137747832.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:12<00:00,  6.87epoch/s, loss=0.00307, prev_loss=0.00298]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.24ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:41:00,498] Trial 139 finished with value: 0.16632407903671265 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.024582196278743924, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2104399205.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:12<00:00,  6.94epoch/s, loss=0.00253, prev_loss=0.00405]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 01:42:12,985] Trial 140 finished with value: 0.1469312459230423 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.025074374113856414, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 811972884.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:58<00:00,  6.89epoch/s, loss=0.00388, prev_loss=0.00223]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.43ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:43:11,426] Trial 141 finished with value: 0.14362935721874237 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03292019389787314, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 619985129.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:01<00:00,  6.53epoch/s, loss=0.00495, prev_loss=0.00594]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.95ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 01:44:13,178] Trial 142 finished with value: 0.11485305428504944 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.020595952781183237, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 598253779.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:12<00:00,  6.87epoch/s, loss=0.00167, prev_loss=0.00271]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.06ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 01:45:26,284] Trial 143 finished with value: 0.15964505076408386 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.027909351839378538, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1095426777.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:16<00:00,  6.56epoch/s, loss=0.00265, prev_loss=0.00199]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.90ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 01:46:43,056] Trial 144 finished with value: 0.13824781775474548 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.0268756012828542, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 641051568.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:12<00:00,  6.94epoch/s, loss=0.00232, prev_loss=0.00175]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.26ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:47:55,468] Trial 145 finished with value: 0.1420002430677414 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02990086950229255, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2084884593.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:11<00:00,  7.02epoch/s, loss=0.00167, prev_loss=0.00176]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.42ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 01:49:07,084] Trial 146 finished with value: 0.14760200679302216 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03495774112176868, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 422516265.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:27<00:00,  6.87epoch/s, loss=0.00335, prev_loss=0.0025] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.63ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 01:50:34,869] Trial 147 finished with value: 0.12715908885002136 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02330686270033923, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2127528594.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:12<00:00,  6.91epoch/s, loss=0.00226, prev_loss=0.00196]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.25ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:51:47,569] Trial 148 finished with value: 0.14833422005176544 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.028523751004387542, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1086389672.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:00<00:00,  6.57epoch/s, loss=0.00336, prev_loss=0.00351]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.36ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 01:52:48,917] Trial 149 finished with value: 0.13734984397888184 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02499221026966902, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1502614144.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:31<00:00,  6.55epoch/s, loss=0.00321, prev_loss=0.00391]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.32ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 01:54:20,901] Trial 150 finished with value: 0.1340155154466629 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.01629632030032703, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1824327599.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.81epoch/s, loss=0.000557, prev_loss=0.000685]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.10ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 01:56:48,254] Trial 151 finished with value: 0.1561466008424759 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03959578844529701, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1200873621.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.88epoch/s, loss=0.000764, prev_loss=0.000612]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.29ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 01:59:13,931] Trial 152 finished with value: 0.15770360827445984 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03848374374052191, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 317083186.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:24<00:00,  6.92epoch/s, loss=0.000603, prev_loss=0.000561]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.10ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 02:01:38,877] Trial 153 finished with value: 0.1489950269460678 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.040840737041249825, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2032450016.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:43<00:00,  6.90epoch/s, loss=0.00428, prev_loss=0.00509]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.13ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 02:02:22,747] Trial 154 finished with value: 0.1473398208618164 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03783897364007001, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 665973570.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.89epoch/s, loss=0.000623, prev_loss=0.000593]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.27ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 02:04:48,180] Trial 155 finished with value: 0.13610181212425232 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03657224272014811, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1613557165.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.51epoch/s, loss=0.000673, prev_loss=0.000639]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.25ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.28s seconds\n",
      "[I 2025-03-05 02:07:22,186] Trial 156 finished with value: 0.13166333734989166 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03258280382209029, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1589099766.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.89epoch/s, loss=0.000544, prev_loss=0.000633]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.25ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 02:09:47,807] Trial 157 finished with value: 0.12601853907108307 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0397610645184489, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1183402549.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:17<00:00,  6.45epoch/s, loss=0.00159, prev_loss=0.002]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.20ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.28s seconds\n",
      "[I 2025-03-05 02:11:05,826] Trial 158 finished with value: 0.12827934324741364 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.0273332299859569, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1928799382.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:11<00:00,  6.83epoch/s, loss=0.00183, prev_loss=0.00174]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.14ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 02:13:18,044] Trial 159 finished with value: 0.13594937324523926 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.01927271146992805, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 674953457.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:35<00:00,  6.44epoch/s, loss=0.000643, prev_loss=0.000559]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.93ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 02:15:53,886] Trial 160 finished with value: 0.14003078639507294 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03565561769872005, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1596007464.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.84epoch/s, loss=0.000668, prev_loss=0.000756]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.48ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 02:18:20,414] Trial 161 finished with value: 0.15541952848434448 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.031276041785643985, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1375836198.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.87epoch/s, loss=0.000803, prev_loss=0.000607]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.28ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 02:20:46,314] Trial 162 finished with value: 0.1152624562382698 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03044259726634271, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1428364847.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.83epoch/s, loss=0.000751, prev_loss=0.000655]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.52ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.29s seconds\n",
      "[I 2025-03-05 02:23:13,215] Trial 163 finished with value: 0.14440259337425232 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03131225588909789, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 758583364.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.84epoch/s, loss=0.000665, prev_loss=0.000759]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.25ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 02:25:39,754] Trial 164 finished with value: 0.14704260230064392 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.025459857093327418, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1826550049.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:30<00:00,  6.63epoch/s, loss=0.000761, prev_loss=0.000625]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.11ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 02:28:10,835] Trial 165 finished with value: 0.1577094942331314 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.029002338707907898, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1120854183.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [03:19<00:00,  5.01epoch/s, loss=0.00101, prev_loss=0.00108] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 795triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.77s seconds\n",
      "[I 2025-03-05 02:31:31,641] Trial 166 finished with value: 0.08931040018796921 and parameters: {'model.embedding_dim': 192, 'optimizer.lr': 0.028644149944864417, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1786831245.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:43<00:00,  6.83epoch/s, loss=0.0157, prev_loss=0.0139]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.53ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 02:32:15,966] Trial 167 finished with value: 0.12326372414827347 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.022234742376082108, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1099515251.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:18<00:00,  6.51epoch/s, loss=0.000761, prev_loss=0.00071] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.34ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 02:34:34,710] Trial 168 finished with value: 0.14814095199108124 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02672664961283016, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1850546770.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [00:58<00:00,  6.87epoch/s, loss=0.0036, prev_loss=0.00295] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 02:35:33,359] Trial 169 finished with value: 0.11045847088098526 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03215838366183128, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1646527854.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.53epoch/s, loss=0.000637, prev_loss=0.000635]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.74ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.36s seconds\n",
      "[I 2025-03-05 02:38:07,027] Trial 170 finished with value: 0.14029449224472046 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.029355024486372533, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 411353468.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:30<00:00,  6.64epoch/s, loss=0.00056, prev_loss=0.000582]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.22ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 02:40:37,944] Trial 171 finished with value: 0.1367763876914978 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03884147864452558, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 567978970.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.82epoch/s, loss=0.000902, prev_loss=0.000693]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.75ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 02:43:04,995] Trial 172 finished with value: 0.13493339717388153 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03422543939020462, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1819518266.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:24<00:00,  6.93epoch/s, loss=0.000764, prev_loss=0.000686]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.55ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 02:45:29,738] Trial 173 finished with value: 0.15366843342781067 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03657203389915132, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 630957624.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.88epoch/s, loss=0.00121, prev_loss=0.0014]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.82ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 02:47:55,313] Trial 174 finished with value: 0.1499001681804657 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.024255206079413456, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 115366251.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.87epoch/s, loss=0.00163, prev_loss=0.000653]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.69ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 02:50:21,352] Trial 175 finished with value: 0.1361672580242157 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03728558794710136, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1289315406.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:25<00:00,  6.85epoch/s, loss=0.000627, prev_loss=0.000622]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.59ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 02:52:47,647] Trial 176 finished with value: 0.1313638985157013 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03189170060980994, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 791000575.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.52epoch/s, loss=0.00064, prev_loss=0.000544]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.33ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 02:55:21,341] Trial 177 finished with value: 0.14901529252529144 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.041999375101654406, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 576201891.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [01:57<00:00,  6.82epoch/s, loss=0.00107, prev_loss=0.000873] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.71ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 02:57:19,083] Trial 178 finished with value: 0.14026738703250885 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.034635551855895286, 'training.num_epochs': 800}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1359295901.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:46<00:00,  6.49epoch/s, loss=0.00591, prev_loss=0.00569]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.51ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 02:58:05,710] Trial 179 finished with value: 0.09861341118812561 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02721242701582145, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1415329394.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:11<00:00,  6.85epoch/s, loss=0.0021, prev_loss=0.00144] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.72ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.11s seconds\n",
      "[I 2025-03-05 03:00:17,501] Trial 180 finished with value: 0.15811854600906372 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0205737388619454, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 400718122.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:11<00:00,  6.85epoch/s, loss=0.00159, prev_loss=0.00163]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.83ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 03:02:29,222] Trial 181 finished with value: 0.14224429428577423 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.01970569092863997, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1173223409.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:11<00:00,  6.83epoch/s, loss=0.000615, prev_loss=0.000598]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.37ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 03:04:41,473] Trial 182 finished with value: 0.1069098711013794 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.07819817442542276, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1280993686.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:42<00:00,  6.84epoch/s, loss=0.00193, prev_loss=0.00195]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.91ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 03:06:24,233] Trial 183 finished with value: 0.14034684002399445 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02199364312898698, 'training.num_epochs': 700}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 703929773.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.83epoch/s, loss=0.000889, prev_loss=0.000821]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.64ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 03:08:50,882] Trial 184 finished with value: 0.13786286115646362 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02429901977997114, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 390904179.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [02:03<00:00,  6.47epoch/s, loss=0.0007, prev_loss=0.000685]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.53ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 03:10:55,007] Trial 185 finished with value: 0.1345423310995102 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.030728798355484095, 'training.num_epochs': 800}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2107208288.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:13<00:00,  6.79epoch/s, loss=0.00147, prev_loss=0.00204]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 03:12:08,993] Trial 186 finished with value: 0.1471860557794571 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03876065029537956, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 865711420.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:34<00:00,  6.47epoch/s, loss=0.000991, prev_loss=0.00132]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.63ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 03:14:43,925] Trial 187 finished with value: 0.14764904975891113 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.018210167568382653, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 334485630.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:27<00:00,  6.79epoch/s, loss=0.000825, prev_loss=0.000831]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 03:17:11,570] Trial 188 finished with value: 0.16933228075504303 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.029242460557394604, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1432707174.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:11<00:00,  6.85epoch/s, loss=0.00101, prev_loss=0.000806] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.72ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 03:19:23,266] Trial 189 finished with value: 0.14299415051937103 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.028902960743909023, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2065216651.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:35<00:00,  6.45epoch/s, loss=0.000671, prev_loss=0.000755]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.35ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 03:21:58,782] Trial 190 finished with value: 0.1510658711194992 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.025616001594409393, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1131965468.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:28<00:00,  6.74epoch/s, loss=0.000622, prev_loss=0.000651]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 03:24:27,530] Trial 191 finished with value: 0.1245696097612381 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03365146760689612, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2141260967.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:28<00:00,  6.75epoch/s, loss=0.000728, prev_loss=0.00102]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.21ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "[I 2025-03-05 03:26:55,982] Trial 192 finished with value: 0.15103484690189362 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.027600369226089137, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1306721150.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:29<00:00,  6.71epoch/s, loss=0.000892, prev_loss=0.000644]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.85ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 03:29:25,446] Trial 193 finished with value: 0.1346888691186905 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03618234582820948, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 771645340.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.83epoch/s, loss=0.000826, prev_loss=0.000772]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 03:31:52,188] Trial 194 finished with value: 0.14894802868366241 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.030661274463844812, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 276976781.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.83epoch/s, loss=0.00148, prev_loss=0.0016]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.88ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 03:34:18,928] Trial 195 finished with value: 0.14264243841171265 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02139592524524757, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 992780781.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:11<00:00,  6.84epoch/s, loss=0.000686, prev_loss=0.000747]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.24ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 03:36:30,856] Trial 196 finished with value: 0.14793063700199127 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03234270719286717, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1086480850.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:01<00:00,  6.51epoch/s, loss=0.00276, prev_loss=0.00291]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 03:37:32,730] Trial 197 finished with value: 0.12345743924379349 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.029444131726441267, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1296772013.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:27<00:00,  6.79epoch/s, loss=0.00175, prev_loss=0.00208]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.33ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 03:40:00,535] Trial 198 finished with value: 0.14718300104141235 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.014373718995827137, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1487941727.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:46<00:00,  6.50epoch/s, loss=0.00187, prev_loss=0.00198]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.47ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 03:40:47,095] Trial 199 finished with value: 0.13212032616138458 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.043978242567826405, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 417020593.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:29<00:00,  6.67epoch/s, loss=0.00125, prev_loss=0.000983]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.53ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 03:43:17,285] Trial 200 finished with value: 0.1498747169971466 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.023206774481492873, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1237523533.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:26<00:00,  6.82epoch/s, loss=0.000597, prev_loss=0.000677]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.49ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 03:45:44,353] Trial 201 finished with value: 0.1380263715982437 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03658139711787797, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2126411286.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:32<00:00,  6.57epoch/s, loss=0.000648, prev_loss=0.000519]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.02ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "[I 2025-03-05 03:48:16,832] Trial 202 finished with value: 0.13132163882255554 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04013487859996188, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 496880525.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:34<00:00,  6.47epoch/s, loss=0.000747, prev_loss=0.000701]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 03:50:51,784] Trial 203 finished with value: 0.11748562753200531 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.033804718624956494, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1450748296.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:48<00:00,  6.48epoch/s, loss=0.000864, prev_loss=0.0009]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.25ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 03:52:40,243] Trial 204 finished with value: 0.15264780819416046 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03807599151384633, 'training.num_epochs': 700}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1363375327.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:16<00:00,  6.50epoch/s, loss=0.00195, prev_loss=0.0018] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.18ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.15s seconds\n",
      "[I 2025-03-05 03:53:57,443] Trial 205 finished with value: 0.14125387370586395 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03580432536202651, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 696451542.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:37<00:00,  6.35epoch/s, loss=0.000922, prev_loss=0.000668]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 03:56:35,226] Trial 206 finished with value: 0.14560876786708832 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.026624588091227766, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1197303957.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:30<00:00,  6.65epoch/s, loss=0.000546, prev_loss=0.000669]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.14ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 03:59:06,056] Trial 207 finished with value: 0.1371302753686905 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04179529917273112, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1934332902.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:30<00:00,  6.65epoch/s, loss=0.00076, prev_loss=0.000678]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 04:01:36,698] Trial 208 finished with value: 0.14845217764377594 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03209855899130568, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1706943627.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:38<00:00,  6.31epoch/s, loss=0.000723, prev_loss=0.0012] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.37ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 04:04:15,665] Trial 209 finished with value: 0.13605186343193054 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.029272451489377998, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 489975239.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:35<00:00,  5.56epoch/s, loss=0.0241, prev_loss=0.0246]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.24ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.49s seconds\n",
      "[I 2025-03-05 04:04:52,309] Trial 210 finished with value: 0.04616008326411247 and parameters: {'model.embedding_dim': 80, 'optimizer.lr': 0.02543333091460529, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 469919192.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [02:00<00:00,  6.61epoch/s, loss=0.000853, prev_loss=0.000859]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.78ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 04:06:53,654] Trial 211 finished with value: 0.14161333441734314 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03805350269489281, 'training.num_epochs': 800}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 485315221.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:30<00:00,  6.66epoch/s, loss=0.000597, prev_loss=0.000594]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.75ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 04:09:24,116] Trial 212 finished with value: 0.11863630264997482 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.039058905619816134, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1551414087.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:30<00:00,  6.63epoch/s, loss=0.00105, prev_loss=0.00125]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.69ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 04:10:54,995] Trial 213 finished with value: 0.14262811839580536 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03562548940881058, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 53114108.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:45<00:00,  6.65epoch/s, loss=0.00126, prev_loss=0.000899] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 04:12:40,586] Trial 214 finished with value: 0.1391824185848236 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03351325768009666, 'training.num_epochs': 700}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1150061033.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 700/700 [01:49<00:00,  6.40epoch/s, loss=0.000837, prev_loss=0.000889]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.82ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 04:14:30,412] Trial 215 finished with value: 0.14166374504566193 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.038359494482917846, 'training.num_epochs': 700}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 628537537.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [02:01<00:00,  6.58epoch/s, loss=0.000743, prev_loss=0.00107] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.70ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 04:16:32,436] Trial 216 finished with value: 0.12268242239952087 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.040425213985791776, 'training.num_epochs': 800}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1097492062.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:31<00:00,  6.59epoch/s, loss=0.000729, prev_loss=0.000663]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 04:19:04,684] Trial 217 finished with value: 0.17019805312156677 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03497081815495673, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 405890040.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:39<00:00,  6.27epoch/s, loss=0.000571, prev_loss=0.000615]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.52ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 04:21:44,706] Trial 218 finished with value: 0.12266892194747925 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.030921212839441267, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1803509492.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:32<00:00,  6.57epoch/s, loss=0.000622, prev_loss=0.000783]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 04:24:17,308] Trial 219 finished with value: 0.1440221071243286 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.034349204776548875, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2007517604.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [03:14<00:00,  5.15epoch/s, loss=0.000876, prev_loss=0.000918]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 944triple/s]  \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.65s seconds\n",
      "[I 2025-03-05 04:27:32,334] Trial 220 finished with value: 0.10538016259670258 and parameters: {'model.embedding_dim': 128, 'optimizer.lr': 0.027767321787729476, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1398403017.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:32<00:00,  6.54epoch/s, loss=0.000624, prev_loss=0.000732]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.63ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "[I 2025-03-05 04:30:05,578] Trial 221 finished with value: 0.1224302425980568 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.036475609532903526, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1346070601.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:15<00:00,  6.60epoch/s, loss=0.00128, prev_loss=0.00122]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "[I 2025-03-05 04:31:21,633] Trial 222 finished with value: 0.12195737659931183 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03753631102896651, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1474743062.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:31<00:00,  6.59epoch/s, loss=0.00071, prev_loss=0.000639]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.79ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 04:33:53,774] Trial 223 finished with value: 0.13401401042938232 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03277395475336788, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1707905929.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:45<00:00,  6.53epoch/s, loss=0.00678, prev_loss=0.00644]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.57ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 04:34:40,072] Trial 224 finished with value: 0.13292527198791504 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.030254728536183755, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1150757153.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:17<00:00,  6.53epoch/s, loss=0.000639, prev_loss=0.0014]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 04:36:58,379] Trial 225 finished with value: 0.15339212119579315 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0356071432834556, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1906346957.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:18<00:00,  6.50epoch/s, loss=0.0008, prev_loss=0.000648]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.91ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 04:39:17,328] Trial 226 finished with value: 0.1494215726852417 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.034709661615271455, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1085760186.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:25<00:00,  6.17epoch/s, loss=0.000844, prev_loss=0.00121] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.03ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 04:41:43,782] Trial 227 finished with value: 0.1349814385175705 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02401995198044926, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 104682694.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:17<00:00,  6.54epoch/s, loss=0.00103, prev_loss=0.000715] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.69ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 04:44:01,856] Trial 228 finished with value: 0.1465228646993637 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03200035640999114, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1007414224.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [03:00<00:00,  4.99epoch/s, loss=0.000971, prev_loss=0.00134] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 841triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.73s seconds\n",
      "[I 2025-03-05 04:47:03,062] Trial 229 finished with value: 0.10410062223672867 and parameters: {'model.embedding_dim': 144, 'optimizer.lr': 0.02782291479020764, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2129913153.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:35<00:00,  6.42epoch/s, loss=0.000736, prev_loss=0.000621]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 04:49:39,209] Trial 230 finished with value: 0.1385715901851654 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03543034440909483, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1509932704.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.51epoch/s, loss=0.000558, prev_loss=0.000509]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.64ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 04:52:13,103] Trial 231 finished with value: 0.13878965377807617 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0392236945931704, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2141132925.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:32<00:00,  6.57epoch/s, loss=0.00077, prev_loss=0.000783]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.15ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.13s seconds\n",
      "[I 2025-03-05 04:54:45,592] Trial 232 finished with value: 0.13677911460399628 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.036982699137776034, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 112307398.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [02:03<00:00,  6.49epoch/s, loss=0.001, prev_loss=0.000645]   \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 04:56:49,113] Trial 233 finished with value: 0.13761980831623077 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.041379451279827256, 'training.num_epochs': 800}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1050044207.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:34<00:00,  6.49epoch/s, loss=0.00066, prev_loss=0.000636]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.92ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 04:59:23,610] Trial 234 finished with value: 0.14278219640254974 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03427926769715104, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1899547020.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:19<00:00,  6.44epoch/s, loss=0.00172, prev_loss=0.00062]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.17ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 05:01:43,792] Trial 235 finished with value: 0.15407976508140564 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04315209250805242, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1663285229.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:26<00:00,  6.16epoch/s, loss=0.000889, prev_loss=0.00106] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.89ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 05:04:10,405] Trial 236 finished with value: 0.1360212117433548 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.020540288298270325, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1854102960.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:18<00:00,  6.49epoch/s, loss=0.000842, prev_loss=0.000874]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.57ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 05:06:29,385] Trial 237 finished with value: 0.14906644821166992 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.042803968205375735, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1864848069.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:17<00:00,  6.52epoch/s, loss=0.000783, prev_loss=0.000601]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.51ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 05:08:47,777] Trial 238 finished with value: 0.1403931826353073 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04460264396926239, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1628424078.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:05<00:00,  6.15epoch/s, loss=0.00129, prev_loss=0.0014]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.88ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 05:09:53,298] Trial 239 finished with value: 0.1410410851240158 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04727145907085789, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 892147882.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:23<00:00,  6.29epoch/s, loss=0.000744, prev_loss=0.00134] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 05:12:16,842] Trial 240 finished with value: 0.14031273126602173 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.029607605756721646, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1189433075.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 800/800 [02:02<00:00,  6.54epoch/s, loss=0.00104, prev_loss=0.000886] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 05:14:19,573] Trial 241 finished with value: 0.14999178051948547 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03918681111497149, 'training.num_epochs': 800}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 942940758.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:32<00:00,  6.55epoch/s, loss=0.000881, prev_loss=0.000565]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.68ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 05:16:52,611] Trial 242 finished with value: 0.13845175504684448 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03710767643914662, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1560306129.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.51epoch/s, loss=0.000562, prev_loss=0.000852]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.42ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 05:19:26,727] Trial 243 finished with value: 0.15311409533023834 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.041129617546514396, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1162965254.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.50epoch/s, loss=0.000755, prev_loss=0.000618]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.42ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 05:22:00,908] Trial 244 finished with value: 0.14006344974040985 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.043435721125091246, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 294476653.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.50epoch/s, loss=0.000506, prev_loss=0.000546]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.52ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 05:24:35,153] Trial 245 finished with value: 0.1292119324207306 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04148028207105908, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 919169800.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [03:04<00:00,  5.42epoch/s, loss=0.00115, prev_loss=0.000854]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.06ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.58s seconds\n",
      "[I 2025-03-05 05:27:40,460] Trial 246 finished with value: 0.12737169861793518 and parameters: {'model.embedding_dim': 96, 'optimizer.lr': 0.026289611340692257, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1908778602.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:46<00:00,  6.44epoch/s, loss=0.00675, prev_loss=0.00625]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.98ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "[I 2025-03-05 05:28:27,361] Trial 247 finished with value: 0.10682272911071777 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03167131769984961, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2117032080.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:42<00:00,  6.15epoch/s, loss=0.000662, prev_loss=0.000658]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.43ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 05:31:10,338] Trial 248 finished with value: 0.13135439157485962 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02840221006059314, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 811186493.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:33<00:00,  6.51epoch/s, loss=0.00061, prev_loss=0.000673]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.20ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 05:33:44,388] Trial 249 finished with value: 0.13676530122756958 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03276998546048281, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 868886376.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:34<00:00,  6.48epoch/s, loss=0.000644, prev_loss=0.000637]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.69ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-05 05:36:19,036] Trial 250 finished with value: 0.13351239264011383 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03508452090375434, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1656298114.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:19<00:00,  6.47epoch/s, loss=0.000699, prev_loss=0.000648]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.02ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 05:38:38,459] Trial 251 finished with value: 0.1506630927324295 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03981896041591501, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 561448848.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:05<00:00,  6.11epoch/s, loss=0.00272, prev_loss=0.00275]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.04ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.30s seconds\n",
      "[I 2025-03-05 05:39:44,375] Trial 252 finished with value: 0.13795605301856995 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.024807469663934295, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 261070671.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:35<00:00,  6.45epoch/s, loss=0.000974, prev_loss=0.000978]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.41ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 05:42:19,839] Trial 253 finished with value: 0.13270962238311768 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.022457242578780262, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1284967033.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:42<00:00,  6.16epoch/s, loss=0.000561, prev_loss=0.000556]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.88ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 05:45:02,776] Trial 254 finished with value: 0.15015481412410736 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04571573999669454, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1724085221.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:17<00:00,  6.45epoch/s, loss=0.00167, prev_loss=0.00141]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.87ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 05:46:20,701] Trial 255 finished with value: 0.1470002979040146 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03013874757331901, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1937654046.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [03:54<00:00,  4.26epoch/s, loss=0.00102, prev_loss=0.0012]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:01<00:00, 438triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 1.39s seconds\n",
      "[I 2025-03-05 05:50:17,133] Trial 256 finished with value: 0.07034631818532944 and parameters: {'model.embedding_dim': 256, 'optimizer.lr': 0.060632978053673944, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 822475994.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:36<00:00,  6.39epoch/s, loss=0.000698, prev_loss=0.000709]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 5.49ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.12s seconds\n",
      "[I 2025-03-05 05:52:53,990] Trial 257 finished with value: 0.11912372708320618 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0413507841935851, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1801027316.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:34<00:00,  6.49epoch/s, loss=0.000677, prev_loss=0.00065]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.89ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 05:55:28,521] Trial 258 finished with value: 0.14333821833133698 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03580347031075193, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1024957320.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 1000/1000 [02:35<00:00,  6.41epoch/s, loss=0.000905, prev_loss=0.00077]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.38ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 05:58:04,831] Trial 259 finished with value: 0.14688237011432648 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03241923907820199, 'training.num_epochs': 1000}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 215405370.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:27<00:00,  6.10epoch/s, loss=0.00117, prev_loss=0.000942] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.94ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 06:00:32,779] Trial 260 finished with value: 0.15364830195903778 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.026595039822462637, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 863740499.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:27<00:00,  6.10epoch/s, loss=0.000835, prev_loss=0.000823]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.41ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 06:03:00,864] Trial 261 finished with value: 0.13268208503723145 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02644144011084694, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 534531713.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:27<00:00,  6.10epoch/s, loss=0.00158, prev_loss=0.00121]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.90ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 06:05:28,978] Trial 262 finished with value: 0.15179382264614105 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.01683150352363203, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1895574371.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:26<00:00,  6.13epoch/s, loss=0.00114, prev_loss=0.000644] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.44ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 06:07:56,321] Trial 263 finished with value: 0.13842421770095825 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02851560239459002, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2051519675.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:35<00:00,  5.79epoch/s, loss=0.00109, prev_loss=0.00103]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.30ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.47s seconds\n",
      "[I 2025-03-05 06:10:32,343] Trial 264 finished with value: 0.13090308010578156 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.023775914177584886, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 874186879.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:49<00:00,  6.09epoch/s, loss=0.00445, prev_loss=0.00495]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.99ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 06:11:22,079] Trial 265 finished with value: 0.12816819548606873 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.0265372141266646, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 884108950.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:19<00:00,  6.45epoch/s, loss=0.000819, prev_loss=0.00105] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.80ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.17s seconds\n",
      "[I 2025-03-05 06:13:41,939] Trial 266 finished with value: 0.14697740972042084 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03022934088128626, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 406631317.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:49<00:00,  5.46epoch/s, loss=0.00184, prev_loss=0.00133]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.40ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.44s seconds\n",
      "[I 2025-03-05 06:15:32,530] Trial 267 finished with value: 0.11158758401870728 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.0250947682179211, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1943634328.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 900/900 [02:38<00:00,  5.68epoch/s, loss=0.000963, prev_loss=0.00137]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.56ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.39s seconds\n",
      "[I 2025-03-05 06:18:11,626] Trial 268 finished with value: 0.12184435874223709 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.020106019907518636, 'training.num_epochs': 900}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 373492644.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:18<00:00,  6.40epoch/s, loss=0.00273, prev_loss=0.00231]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.36ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 06:19:30,175] Trial 269 finished with value: 0.1543109118938446 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.028786575898643328, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 17250312.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:22<00:00,  6.06epoch/s, loss=0.00153, prev_loss=0.00154]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.95ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 06:20:53,124] Trial 270 finished with value: 0.14284177124500275 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.027590529223153075, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 59258105.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:18<00:00,  6.41epoch/s, loss=0.00206, prev_loss=0.00238]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.08ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 06:22:11,513] Trial 271 finished with value: 0.14535659551620483 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.028728206370253483, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1383477687.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:22<00:00,  6.08epoch/s, loss=0.00143, prev_loss=0.00165]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 06:23:34,293] Trial 272 finished with value: 0.153547003865242 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03147687612545383, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 667328341.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:37<00:00,  5.11epoch/s, loss=0.00149, prev_loss=0.0013] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 985triple/s]  \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.62s seconds\n",
      "[I 2025-03-05 06:25:13,001] Trial 273 finished with value: 0.10834704339504242 and parameters: {'model.embedding_dim': 112, 'optimizer.lr': 0.031474909917226825, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 894424625.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:11<00:00,  5.56epoch/s, loss=0.00239, prev_loss=0.00239]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.38s seconds\n",
      "[I 2025-03-05 06:26:25,485] Trial 274 finished with value: 0.1276286393404007 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.02998298940259261, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1308645604.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:46<00:00,  4.69epoch/s, loss=0.00182, prev_loss=0.00227]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 748triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.82s seconds\n",
      "[I 2025-03-05 06:28:13,140] Trial 275 finished with value: 0.06393945217132568 and parameters: {'model.embedding_dim': 176, 'optimizer.lr': 0.02597579951512318, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1174877927.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:22<00:00,  6.05epoch/s, loss=0.00256, prev_loss=0.00254]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.47ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 06:29:36,286] Trial 276 finished with value: 0.12837858498096466 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.022453914281092696, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1840181863.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:21<00:00,  6.15epoch/s, loss=0.0017, prev_loss=0.00189] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.44ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 06:30:58,082] Trial 277 finished with value: 0.1539439857006073 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.027721280575533937, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1953340836.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:32<00:00,  6.07epoch/s, loss=0.021, prev_loss=0.0202] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 06:31:31,480] Trial 278 finished with value: 0.08357913047075272 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.027231697220085362, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1630411569.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:25<00:00,  5.83epoch/s, loss=0.000925, prev_loss=0.000822]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.03ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 06:32:57,747] Trial 279 finished with value: 0.12581321597099304 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.06793937299303715, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1062293866.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 100/100 [00:15<00:00,  6.34epoch/s, loss=0.663, prev_loss=0.657]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.15ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 06:33:13,886] Trial 280 finished with value: 0.0050849574618041515 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.023963830903296686, 'training.num_epochs': 100}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1547070635.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:18<00:00,  6.38epoch/s, loss=0.00334, prev_loss=0.00275]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.56ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 06:34:32,650] Trial 281 finished with value: 0.1607488989830017 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02757917024075033, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1260078297.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:17<00:00,  6.43epoch/s, loss=0.00242, prev_loss=0.00226]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.79ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 06:35:50,810] Trial 282 finished with value: 0.15523013472557068 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02887860122965167, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1975713637.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:19<00:00,  6.29epoch/s, loss=0.0019, prev_loss=0.00314] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.28ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 06:37:10,630] Trial 283 finished with value: 0.12563833594322205 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02883422875921917, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2044171583.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:19<00:00,  6.26epoch/s, loss=0.00254, prev_loss=0.00203]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.43ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 06:38:30,825] Trial 284 finished with value: 0.1553923785686493 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.029272314542175323, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 234957574.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:20<00:00,  6.18epoch/s, loss=0.000741, prev_loss=0.00102] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 4.72ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.14s seconds\n",
      "[I 2025-03-05 06:39:52,043] Trial 285 finished with value: 0.1408262699842453 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.09913292300899582, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1559713022.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:20<00:00,  6.20epoch/s, loss=0.00306, prev_loss=0.00221]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.91ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "[I 2025-03-05 06:41:13,028] Trial 286 finished with value: 0.14838029444217682 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.029257435078400278, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 125166680.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:20<00:00,  6.25epoch/s, loss=0.00215, prev_loss=0.002]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.63ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 06:42:33,517] Trial 287 finished with value: 0.1481289118528366 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.030475472673426842, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 20758005.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [02:03<00:00,  4.06epoch/s, loss=0.00187, prev_loss=0.00179]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 624triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.98s seconds\n",
      "[I 2025-03-05 06:44:37,995] Trial 288 finished with value: 0.059473637491464615 and parameters: {'model.embedding_dim': 208, 'optimizer.lr': 0.024965883435659236, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1285361933.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.37epoch/s, loss=0.00201, prev_loss=0.00186]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.03ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 06:46:11,499] Trial 289 finished with value: 0.15584319829940796 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03345920731445333, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1749952274.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.39epoch/s, loss=0.00147, prev_loss=0.00135]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.42ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 06:47:44,740] Trial 290 finished with value: 0.12211669236421585 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.034242198125892985, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 788318385.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:50<00:00,  5.41epoch/s, loss=0.00179, prev_loss=0.00129]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 06:49:36,016] Trial 291 finished with value: 0.14842930436134338 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03310103943014988, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1480216107.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.40epoch/s, loss=0.0019, prev_loss=0.00313] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 06:51:09,090] Trial 292 finished with value: 0.1449257880449295 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03177943526604074, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1964343728.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.39epoch/s, loss=0.00143, prev_loss=0.00172]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 06:52:42,292] Trial 293 finished with value: 0.15719884634017944 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.033204702944277326, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 823299681.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.38epoch/s, loss=0.0017, prev_loss=0.00181] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.00ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 06:54:15,527] Trial 294 finished with value: 0.15132075548171997 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03350532703278489, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 345267194.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.38epoch/s, loss=0.00177, prev_loss=0.0024] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.83ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 06:55:48,841] Trial 295 finished with value: 0.1364024579524994 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03047663599511389, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1883235028.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.34epoch/s, loss=0.00215, prev_loss=0.00221]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 06:57:22,862] Trial 296 finished with value: 0.1595667153596878 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03317967292992731, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1507339003.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.00199, prev_loss=0.00257]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 06:58:56,490] Trial 297 finished with value: 0.16236931085586548 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.032947675897034186, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1972226672.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.39epoch/s, loss=0.00181, prev_loss=0.00227]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.31ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 07:00:29,565] Trial 298 finished with value: 0.1569867730140686 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.033692284511936996, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 501350722.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.41epoch/s, loss=0.00335, prev_loss=0.00205]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.57ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:02:02,400] Trial 299 finished with value: 0.1483212262392044 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.033358676526299605, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1153762403.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.39epoch/s, loss=0.00213, prev_loss=0.00141]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.51ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:03:35,605] Trial 300 finished with value: 0.1404382735490799 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03362090102548905, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 714502649.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.37epoch/s, loss=0.00209, prev_loss=0.00146]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.50ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:05:09,091] Trial 301 finished with value: 0.14722371101379395 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03174633457304881, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 838886584.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [02:20<00:00,  4.27epoch/s, loss=0.00123, prev_loss=0.00112]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 786triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.78s seconds\n",
      "[I 2025-03-05 07:07:30,648] Trial 302 finished with value: 0.09875735640525818 and parameters: {'model.embedding_dim': 160, 'optimizer.lr': 0.03500286357534135, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1218595335.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.00195, prev_loss=0.0015] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.29ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 07:09:04,296] Trial 303 finished with value: 0.15485551953315735 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.032403416516650865, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1228408914.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.35epoch/s, loss=0.00154, prev_loss=0.0016] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.55ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:10:38,235] Trial 304 finished with value: 0.151988685131073 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03457548542857219, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 110241269.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.16epoch/s, loss=0.00328, prev_loss=0.00314]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.74ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 07:11:56,208] Trial 305 finished with value: 0.140527606010437 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03122139953735521, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 120695650.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.33epoch/s, loss=0.00183, prev_loss=0.00204]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.42ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 07:13:30,396] Trial 306 finished with value: 0.15330959856510162 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03740835561864204, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1142119769.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.0022, prev_loss=0.0025]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:15:04,127] Trial 307 finished with value: 0.14502786099910736 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03380270497382468, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1459773189.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.00223, prev_loss=0.00186]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:16:37,810] Trial 308 finished with value: 0.11159229278564453 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02986752611838411, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1752860578.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.16epoch/s, loss=0.00135, prev_loss=0.002]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.83ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.34s seconds\n",
      "[I 2025-03-05 07:17:55,827] Trial 309 finished with value: 0.14030689001083374 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03628104425931733, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2064427361.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.35epoch/s, loss=0.0015, prev_loss=0.0015]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.59ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:19:29,622] Trial 310 finished with value: 0.1514338254928589 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03171559661310194, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1751832704.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.34epoch/s, loss=0.00212, prev_loss=0.00203]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.68ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 07:21:03,643] Trial 311 finished with value: 0.1575428545475006 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.030447276549953887, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1633361052.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:34<00:00,  5.31epoch/s, loss=0.00152, prev_loss=0.00255]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.32ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 07:22:38,294] Trial 312 finished with value: 0.15410232543945312 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03332999923619501, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1551634353.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.0021, prev_loss=0.00232] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.10ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 07:24:11,960] Trial 313 finished with value: 0.13216948509216309 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.030084969155976284, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 849720643.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.33epoch/s, loss=0.00144, prev_loss=0.00163]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.53ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:25:46,164] Trial 314 finished with value: 0.14187541604042053 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.037839614154351574, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 594799319.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:29<00:00,  4.49epoch/s, loss=0.00144, prev_loss=0.00164]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.21ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.51s seconds\n",
      "[I 2025-03-05 07:27:16,030] Trial 315 finished with value: 0.1295279711484909 and parameters: {'model.embedding_dim': 80, 'optimizer.lr': 0.03539369964944831, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1821744099.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.34epoch/s, loss=0.00488, prev_loss=0.0048] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:28:50,121] Trial 316 finished with value: 0.13632133603096008 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.01914478816028912, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 143900309.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:51<00:00,  5.37epoch/s, loss=0.0014, prev_loss=0.000564]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:30:42,308] Trial 317 finished with value: 0.14406941831111908 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0710427647555994, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 289582417.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.39epoch/s, loss=0.00192, prev_loss=0.00255]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:32:15,557] Trial 318 finished with value: 0.14422596991062164 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.028589145058037745, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 16923209.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.00152, prev_loss=0.00129]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:33:49,315] Trial 319 finished with value: 0.1378047615289688 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03498973881288934, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 312018914.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.34epoch/s, loss=0.00181, prev_loss=0.00335]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.51ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:35:23,286] Trial 320 finished with value: 0.14909009635448456 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.030444092296930715, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1767438108.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.37epoch/s, loss=0.00703, prev_loss=0.00834]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:36:38,195] Trial 321 finished with value: 0.12507154047489166 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.021228578073938523, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 619922535.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.00161, prev_loss=0.002]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.79ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 07:38:11,863] Trial 322 finished with value: 0.14064548909664154 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03217393593547901, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1471465966.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:56<00:00,  5.15epoch/s, loss=0.00155, prev_loss=0.00216]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.76ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.35s seconds\n",
      "[I 2025-03-05 07:40:08,914] Trial 323 finished with value: 0.14953181147575378 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.027518794468352866, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 939016375.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.37epoch/s, loss=0.00129, prev_loss=0.00132]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:41:42,565] Trial 324 finished with value: 0.1376989483833313 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03841876539240013, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 400866691.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:41<00:00,  3.93epoch/s, loss=0.00169, prev_loss=0.00208]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:01<00:00, 565triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 1.08s seconds\n",
      "[I 2025-03-05 07:43:25,856] Trial 325 finished with value: 0.0558159239590168 and parameters: {'model.embedding_dim': 240, 'optimizer.lr': 0.0330919948018119, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1632937512.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.34epoch/s, loss=0.00414, prev_loss=0.00353]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.06ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 07:44:22,378] Trial 326 finished with value: 0.16071654856204987 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03644586522056583, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2121587145.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.32epoch/s, loss=0.00394, prev_loss=0.00378]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:45:19,139] Trial 327 finished with value: 0.14152124524116516 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.036401644909701186, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 927323590.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:58<00:00,  5.15epoch/s, loss=0.00257, prev_loss=0.00283]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.78ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.35s seconds\n",
      "[I 2025-03-05 07:46:17,883] Trial 328 finished with value: 0.11543665081262589 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03856304795578723, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2048541910.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.35epoch/s, loss=0.00353, prev_loss=0.00423]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.55ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:47:14,474] Trial 329 finished with value: 0.15129923820495605 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03644327695556527, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1923798710.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.35epoch/s, loss=0.00489, prev_loss=0.00545]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:48:10,999] Trial 330 finished with value: 0.14738118648529053 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.034428484087197134, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 987512545.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:57<00:00,  5.20epoch/s, loss=0.00157, prev_loss=0.00168]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.90ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 07:49:09,141] Trial 331 finished with value: 0.15396790206432343 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.05148496433035721, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1104321492.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.34epoch/s, loss=0.00413, prev_loss=0.00409]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.37ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 07:50:05,725] Trial 332 finished with value: 0.16172918677330017 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.039629862715861726, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 640492733.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.35epoch/s, loss=0.00401, prev_loss=0.00318]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.41ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 07:51:02,271] Trial 333 finished with value: 0.14893083274364471 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03926597875670287, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 212802363.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.34epoch/s, loss=0.00525, prev_loss=0.00415]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.33ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 07:51:58,852] Trial 334 finished with value: 0.1356678605079651 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03720696082544539, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 487172276.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.32epoch/s, loss=0.00255, prev_loss=0.00414]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 07:52:55,613] Trial 335 finished with value: 0.14842095971107483 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04075894399613999, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 373230057.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:57<00:00,  5.18epoch/s, loss=0.00222, prev_loss=0.00258]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.89ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 07:53:54,091] Trial 336 finished with value: 0.14079777896404266 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.03986529883301301, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 165027203.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.32epoch/s, loss=0.00481, prev_loss=0.00431]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.56ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 07:54:50,933] Trial 337 finished with value: 0.1495545208454132 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03503168577293248, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1922613926.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:56<00:00,  5.29epoch/s, loss=0.0237, prev_loss=0.0223]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.38ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 07:55:48,121] Trial 338 finished with value: 0.11179743707180023 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.018154488137499085, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 819450324.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.27epoch/s, loss=0.0025, prev_loss=0.00335] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.40ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 07:57:04,437] Trial 339 finished with value: 0.15673302114009857 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03773475188672881, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1515171847.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.13epoch/s, loss=0.00242, prev_loss=0.00255]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.78ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.35s seconds\n",
      "[I 2025-03-05 07:58:22,880] Trial 340 finished with value: 0.14133845269680023 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.037680951743870615, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 190728754.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.31epoch/s, loss=0.00227, prev_loss=0.00283]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.70ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 07:59:38,602] Trial 341 finished with value: 0.11914174258708954 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0397476039420993, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1224870699.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.35epoch/s, loss=0.00167, prev_loss=0.00144]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:00:53,709] Trial 342 finished with value: 0.15768511593341827 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.042436258971613024, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2069095183.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.36epoch/s, loss=0.00155, prev_loss=0.0027] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.82ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 08:02:08,714] Trial 343 finished with value: 0.15285499393939972 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04308650196238818, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 976100658.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.34epoch/s, loss=0.00214, prev_loss=0.00248]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.64ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:03:24,055] Trial 344 finished with value: 0.15701425075531006 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04914617455056292, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 483133697.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.13epoch/s, loss=0.00181, prev_loss=0.00135]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.94ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 08:04:42,507] Trial 345 finished with value: 0.13859803974628448 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04259186213735152, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1590514200.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.32epoch/s, loss=0.00124, prev_loss=0.00231]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.07ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 08:05:58,070] Trial 346 finished with value: 0.1498182713985443 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04511269424493039, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 412119525.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.15epoch/s, loss=0.000886, prev_loss=0.000811]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.83ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.34s seconds\n",
      "[I 2025-03-05 08:07:16,309] Trial 347 finished with value: 0.16202843189239502 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04899715797288705, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 542727456.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.35epoch/s, loss=0.00189, prev_loss=0.00149]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.52ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 08:08:31,517] Trial 348 finished with value: 0.14017044007778168 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04852314386134316, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1726481162.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.29epoch/s, loss=0.0015, prev_loss=0.00168] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.53ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 08:09:47,534] Trial 349 finished with value: 0.11581554263830185 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0480688161479938, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1591005023.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:18<00:00,  5.12epoch/s, loss=0.00142, prev_loss=0.00115]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.86ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 08:11:06,160] Trial 350 finished with value: 0.13498827815055847 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04651379068528561, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 962938287.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.34epoch/s, loss=0.00116, prev_loss=0.00112]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.11ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 08:12:21,471] Trial 351 finished with value: 0.14088980853557587 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05513075076203705, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2104804878.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.35epoch/s, loss=0.00166, prev_loss=0.0017] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.45ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 08:13:36,645] Trial 352 finished with value: 0.12957404553890228 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05233005207961546, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 726042170.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:18<00:00,  5.11epoch/s, loss=0.00115, prev_loss=0.000906] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.75ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.36s seconds\n",
      "[I 2025-03-05 08:14:55,446] Trial 353 finished with value: 0.12273874133825302 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04836694984819724, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 612988583.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.14epoch/s, loss=0.00285, prev_loss=0.00127]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:16:13,801] Trial 354 finished with value: 0.14478515088558197 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04514464395074493, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1593472402.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.34epoch/s, loss=0.0021, prev_loss=0.00235] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.26ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 08:17:29,058] Trial 355 finished with value: 0.14959649741649628 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.043193311487236284, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1944590036.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.36epoch/s, loss=0.00163, prev_loss=0.002]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.81ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 08:18:44,021] Trial 356 finished with value: 0.15239056944847107 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.057270965746652414, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 407022500.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:33<00:00,  4.28epoch/s, loss=0.00111, prev_loss=0.00117]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 787triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.78s seconds\n",
      "[I 2025-03-05 08:20:18,518] Trial 357 finished with value: 0.09330499172210693 and parameters: {'model.embedding_dim': 144, 'optimizer.lr': 0.05150261399991045, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1575601154.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.13epoch/s, loss=0.00138, prev_loss=0.0013] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.87ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 08:21:36,941] Trial 358 finished with value: 0.13735832273960114 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.0401645731627345, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2051158569.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:37<00:00,  5.31epoch/s, loss=0.00657, prev_loss=0.00772]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.39ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 08:22:15,031] Trial 359 finished with value: 0.12857064604759216 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.050005861756976744, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1269927305.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.32epoch/s, loss=0.00132, prev_loss=0.00144] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:23:30,699] Trial 360 finished with value: 0.13173064589500427 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0531666538714423, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 181422569.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.33epoch/s, loss=0.00158, prev_loss=0.00198]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.57ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:24:46,102] Trial 361 finished with value: 0.10782481729984283 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04184750842758002, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1923179803.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.31epoch/s, loss=0.0023, prev_loss=0.00165] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.44ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 08:26:01,891] Trial 362 finished with value: 0.16202831268310547 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04450013969299308, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1783647682.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.29epoch/s, loss=0.00174, prev_loss=0.00174]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 08:27:17,890] Trial 363 finished with value: 0.15886318683624268 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04407785951014736, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 589545825.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.15epoch/s, loss=0.00106, prev_loss=0.00137]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.93ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 08:28:36,037] Trial 364 finished with value: 0.13562148809432983 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04662967003424116, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1720762882.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.33epoch/s, loss=0.00147, prev_loss=0.00163]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.64ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:29:51,454] Trial 365 finished with value: 0.14025063812732697 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.044618739365510564, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1023719656.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.34epoch/s, loss=0.00173, prev_loss=0.0014] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.26ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 08:31:06,694] Trial 366 finished with value: 0.1465342789888382 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04939409954787342, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 265141294.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.34epoch/s, loss=0.00161, prev_loss=0.00167]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.05ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 08:32:21,982] Trial 367 finished with value: 0.1489611268043518 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04381009465154496, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 899695449.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.16epoch/s, loss=0.0013, prev_loss=0.00101] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.95ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 08:33:40,011] Trial 368 finished with value: 0.12999668717384338 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.05018568766777506, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1459270420.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.33epoch/s, loss=0.00229, prev_loss=0.00173]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.97ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 08:34:55,484] Trial 369 finished with value: 0.1364375203847885 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0463295171738721, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1479971561.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:17<00:00,  5.13epoch/s, loss=0.000937, prev_loss=0.00102]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.91ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 08:36:13,929] Trial 370 finished with value: 0.15301108360290527 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04626428281894307, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 689363380.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.33epoch/s, loss=0.00151, prev_loss=0.0017] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.79ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 08:37:29,354] Trial 371 finished with value: 0.14981621503829956 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04202815044286709, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 214671026.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:36<00:00,  4.14epoch/s, loss=0.00163, prev_loss=0.00153]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 672triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.91s seconds\n",
      "[I 2025-03-05 08:39:07,105] Trial 372 finished with value: 0.08610758185386658 and parameters: {'model.embedding_dim': 192, 'optimizer.lr': 0.04458076468559934, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1091493733.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:52<00:00,  5.32epoch/s, loss=0.00115, prev_loss=0.000702] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.16ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 08:41:00,277] Trial 373 finished with value: 0.12321912497282028 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04182200215290025, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 439577767.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:14<00:00,  5.35epoch/s, loss=0.001, prev_loss=0.00145]    \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.65ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:42:15,410] Trial 374 finished with value: 0.15244165062904358 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.08729945600621578, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 66154463.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:16<00:00,  5.26epoch/s, loss=0.00158, prev_loss=0.00172]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.70ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 08:43:31,854] Trial 375 finished with value: 0.1396043598651886 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.048718762188650226, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1540767513.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.32epoch/s, loss=0.00219, prev_loss=0.00223]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 08:44:47,402] Trial 376 finished with value: 0.15505704283714294 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.041014128332594685, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 738775023.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:58<00:00,  5.15epoch/s, loss=0.00253, prev_loss=0.00274]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.03ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 08:45:46,189] Trial 377 finished with value: 0.15368255972862244 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.043693215531691976, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1263966060.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.40epoch/s, loss=0.00159, prev_loss=0.00117]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 08:47:19,261] Trial 378 finished with value: 0.14944569766521454 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.038757693226384275, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1368593025.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.42epoch/s, loss=0.00109, prev_loss=0.000831] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.79ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 08:48:51,979] Trial 379 finished with value: 0.15799105167388916 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.045738436059937694, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 759915107.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:35<00:00,  5.22epoch/s, loss=0.00121, prev_loss=0.00105]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.98ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 08:50:28,221] Trial 380 finished with value: 0.110854871571064 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04582722773199991, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 680682146.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:32<00:00,  5.40epoch/s, loss=0.000771, prev_loss=0.000954]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.82ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 08:52:01,137] Trial 381 finished with value: 0.15180987119674683 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.047918924869871975, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 185374809.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:58<00:00,  4.20epoch/s, loss=0.00119, prev_loss=0.00127]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 685triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.89s seconds\n",
      "[I 2025-03-05 08:54:01,289] Trial 382 finished with value: 0.09210184961557388 and parameters: {'model.embedding_dim': 176, 'optimizer.lr': 0.04348876684522421, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1382203587.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.36epoch/s, loss=0.00137, prev_loss=0.00169] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.76ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.36s seconds\n",
      "[I 2025-03-05 08:55:35,129] Trial 383 finished with value: 0.14382150769233704 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04782258749172893, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 461570308.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:33<00:00,  5.34epoch/s, loss=0.00112, prev_loss=0.00114] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.83ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.22s seconds\n",
      "[I 2025-03-05 08:57:09,210] Trial 384 finished with value: 0.1613817662000656 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05008957182095071, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 373469908.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:37<00:00,  5.15epoch/s, loss=0.000828, prev_loss=0.000823]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.88ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.33s seconds\n",
      "[I 2025-03-05 08:58:46,905] Trial 385 finished with value: 0.1473694145679474 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.050011457410648164, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 197954731.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:33<00:00,  6.43epoch/s, loss=0.000744, prev_loss=0.00099] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.90ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "[I 2025-03-05 09:00:20,498] Trial 386 finished with value: 0.150655135512352 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.053006664402707133, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1232218618.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:24<00:00,  5.93epoch/s, loss=0.00098, prev_loss=0.00086]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.38s seconds\n",
      "[I 2025-03-05 09:01:45,460] Trial 387 finished with value: 0.12024183571338654 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.051194962620985884, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 831301272.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:52<00:00,  5.73epoch/s, loss=0.00269, prev_loss=0.00266]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.06ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 09:02:38,193] Trial 388 finished with value: 0.1341869980096817 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.045020595409679676, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1404109764.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:21<00:00,  6.14epoch/s, loss=0.00101, prev_loss=0.000979] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.26ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 09:03:59,970] Trial 389 finished with value: 0.13268527388572693 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0465170423346058, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 194366096.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:18<00:00,  6.33epoch/s, loss=0.000922, prev_loss=0.000841]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.18ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.29s seconds\n",
      "[I 2025-03-05 09:05:19,445] Trial 390 finished with value: 0.15459516644477844 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.047439302850896904, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1478300806.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:16<00:00,  6.50epoch/s, loss=0.00105, prev_loss=0.00106]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.55ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 09:06:36,658] Trial 391 finished with value: 0.1335279643535614 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05377644055022824, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1969144415.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:46<00:00,  6.49epoch/s, loss=0.00265, prev_loss=0.00239]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.77ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 09:07:23,307] Trial 392 finished with value: 0.1688246876001358 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04970919320962793, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 245220281.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:32<00:00,  6.22epoch/s, loss=0.00557, prev_loss=0.004]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.08ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.30s seconds\n",
      "[I 2025-03-05 09:07:55,953] Trial 393 finished with value: 0.14775006473064423 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.042705662719940383, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1616052028.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:46<00:00,  6.47epoch/s, loss=0.00237, prev_loss=0.00289]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.96ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.16s seconds\n",
      "[I 2025-03-05 09:08:42,705] Trial 394 finished with value: 0.15779058635234833 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.051049954488588206, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 913496870.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:46<00:00,  6.39epoch/s, loss=0.00337, prev_loss=0.00283]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.35ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 09:09:30,066] Trial 395 finished with value: 0.1486975997686386 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05144279252799493, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1460579558.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:47<00:00,  6.33epoch/s, loss=0.00198, prev_loss=0.0028] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.60ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 09:10:17,810] Trial 396 finished with value: 0.13826221227645874 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05105721810746469, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1093471337.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:47<00:00,  6.38epoch/s, loss=0.00193, prev_loss=0.00206]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.39ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 09:11:05,248] Trial 397 finished with value: 0.14413227140903473 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05622454140681582, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 966608297.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:49<00:00,  6.06epoch/s, loss=0.00197, prev_loss=0.00176]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.10ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.30s seconds\n",
      "[I 2025-03-05 09:11:55,302] Trial 398 finished with value: 0.15168142318725586 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.054619116874740255, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1612193263.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:47<00:00,  6.31epoch/s, loss=0.0022, prev_loss=0.00286] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.57ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 09:12:43,259] Trial 399 finished with value: 0.13704486191272736 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05008325157267348, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 585767148.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:51<00:00,  5.86epoch/s, loss=0.00144, prev_loss=0.00157]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.50ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.41s seconds\n",
      "[I 2025-03-05 09:13:35,107] Trial 400 finished with value: 0.1356644481420517 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.04664849751491798, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1962786407.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:47<00:00,  6.28epoch/s, loss=0.00307, prev_loss=0.00259]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.43ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.18s seconds\n",
      "[I 2025-03-05 09:14:23,266] Trial 401 finished with value: 0.13353534042835236 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.0448080605605765, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 413720088.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:49<00:00,  6.06epoch/s, loss=0.0015, prev_loss=0.00229] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.23ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.28s seconds\n",
      "[I 2025-03-05 09:15:13,264] Trial 402 finished with value: 0.14227959513664246 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05332340130483066, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1604133684.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:52<00:00,  5.70epoch/s, loss=0.0021, prev_loss=0.00172] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.83ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.34s seconds\n",
      "[I 2025-03-05 09:16:06,454] Trial 403 finished with value: 0.13731497526168823 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04873431644919532, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1797938720.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:59<00:00,  5.01epoch/s, loss=0.91, prev_loss=0.936] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 923triple/s]  \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.66s seconds\n",
      "[I 2025-03-05 09:17:07,204] Trial 404 finished with value: 0.002887427108362317 and parameters: {'model.embedding_dim': 112, 'optimizer.lr': 0.0058211670902086, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 349088281.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:38<00:00,  5.24epoch/s, loss=0.272, prev_loss=0.28] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.04ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.59s seconds\n",
      "[I 2025-03-05 09:17:46,167] Trial 405 finished with value: 0.003809986636042595 and parameters: {'model.embedding_dim': 96, 'optimizer.lr': 0.012392584437531877, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1517521779.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:48<00:00,  6.24epoch/s, loss=0.00312, prev_loss=0.00315]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.07ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 09:18:34,608] Trial 406 finished with value: 0.14033973217010498 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04499887638989108, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 351101081.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:49<00:00,  6.08epoch/s, loss=0.00215, prev_loss=0.00229]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.30ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 09:19:24,383] Trial 407 finished with value: 0.15316787362098694 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04940056811584194, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1105930285.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:53<00:00,  5.65epoch/s, loss=0.00575, prev_loss=0.00566]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.00ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 09:20:18,111] Trial 408 finished with value: 0.12365962564945221 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.025100228581235062, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1798191195.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:50<00:00,  5.95epoch/s, loss=0.00347, prev_loss=0.00351]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.50ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 09:21:08,989] Trial 409 finished with value: 0.14203989505767822 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.041809608412566056, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1289053711.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [01:43<00:00,  5.80epoch/s, loss=0.00105, prev_loss=0.000869] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.72ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.23s seconds\n",
      "[I 2025-03-05 09:22:52,788] Trial 410 finished with value: 0.14416714012622833 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04768897386945574, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 208108416.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:29<00:00,  5.59epoch/s, loss=0.00348, prev_loss=0.00358]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.41ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 09:24:22,693] Trial 411 finished with value: 0.15411584079265594 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02323694033985755, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1307164162.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:52<00:00,  5.66epoch/s, loss=0.00207, prev_loss=0.00217]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.93ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.32s seconds\n",
      "[I 2025-03-05 09:25:16,176] Trial 412 finished with value: 0.13733670115470886 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.0406181949384717, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1463636069.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:36<00:00,  5.48epoch/s, loss=0.00752, prev_loss=0.00714]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.37ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 09:25:53,118] Trial 413 finished with value: 0.09532012045383453 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04337086817426989, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 314186078.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:29<00:00,  5.57epoch/s, loss=0.00122, prev_loss=0.00105]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 09:27:23,370] Trial 414 finished with value: 0.13253183662891388 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05178034694569202, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2119544831.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:12<00:00,  5.52epoch/s, loss=0.00455, prev_loss=0.00505]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 09:28:36,255] Trial 415 finished with value: 0.12069482356309891 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.026563488954904513, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 325894281.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:44<00:00,  4.80epoch/s, loss=0.00148, prev_loss=0.000993]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.29ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 09:30:20,866] Trial 416 finished with value: 0.15492308139801025 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04629601558796989, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1325566857.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [01:03<00:00,  4.71epoch/s, loss=0.00188, prev_loss=0.00161]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.56ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.40s seconds\n",
      "[I 2025-03-05 09:31:25,274] Trial 417 finished with value: 0.15201398730278015 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.043583039380660674, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1870641845.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [02:05<00:00,  3.98epoch/s, loss=0.000938, prev_loss=0.00129]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 899triple/s]  \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.68s seconds\n",
      "[I 2025-03-05 09:33:31,775] Trial 418 finished with value: 0.1305321902036667 and parameters: {'model.embedding_dim': 80, 'optimizer.lr': 0.04029103273568789, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1437637584.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [02:04<00:00,  4.83epoch/s, loss=0.00104, prev_loss=0.000937] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.40ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.26s seconds\n",
      "[I 2025-03-05 09:35:36,552] Trial 419 finished with value: 0.14017324149608612 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04951431373482539, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 209231972.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:19<00:00,  5.04epoch/s, loss=0.0036, prev_loss=0.00355] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.01ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.21s seconds\n",
      "[I 2025-03-05 09:36:56,292] Trial 420 finished with value: 0.12910427153110504 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02712298718746868, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 162124964.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:41<00:00,  4.91epoch/s, loss=0.00104, prev_loss=0.000931] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.58ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.39s seconds\n",
      "[I 2025-03-05 09:38:38,752] Trial 421 finished with value: 0.14676594734191895 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04561638415878988, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1867248857.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:58<00:00,  5.13epoch/s, loss=0.00274, prev_loss=0.00285]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.21ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 09:39:37,630] Trial 422 finished with value: 0.14516378939151764 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.047159050199344174, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 194780360.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:31<00:00,  4.35epoch/s, loss=0.00382, prev_loss=0.00392]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.10ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.56s seconds\n",
      "[I 2025-03-05 09:41:10,472] Trial 423 finished with value: 0.1136510893702507 and parameters: {'model.embedding_dim': 64, 'optimizer.lr': 0.02309797098611716, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1494503429.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 100/100 [00:19<00:00,  5.08epoch/s, loss=0.0539, prev_loss=0.0617]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.46ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 09:41:30,640] Trial 424 finished with value: 0.0770498588681221 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.06397711492202324, 'training.num_epochs': 100}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2115718739.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:39<00:00,  5.01epoch/s, loss=0.00265, prev_loss=0.00254]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.24s seconds\n",
      "[I 2025-03-05 09:43:10,962] Trial 425 finished with value: 0.1289668083190918 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.025321803455314294, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 840910328.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:26<00:00,  4.62epoch/s, loss=0.00162, prev_loss=0.00122]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.62ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.38s seconds\n",
      "[I 2025-03-05 09:44:38,173] Trial 426 finished with value: 0.15049096941947937 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04114252605718411, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 521823449.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:40<00:00,  4.97epoch/s, loss=0.00169, prev_loss=0.0014]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.17ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.20s seconds\n",
      "[I 2025-03-05 09:46:19,197] Trial 427 finished with value: 0.154656320810318 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.03909215358684464, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 120198937.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [01:00<00:00,  4.99epoch/s, loss=0.00265, prev_loss=0.00183]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.28ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.28s seconds\n",
      "[I 2025-03-05 09:47:19,860] Trial 428 finished with value: 0.15445534884929657 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.050312100261372436, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 346110451.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:23<00:00,  4.78epoch/s, loss=0.00102, prev_loss=0.00135]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.61ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.39s seconds\n",
      "[I 2025-03-05 09:48:44,194] Trial 429 finished with value: 0.15532977879047394 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04263087311812545, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1834372106.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:20<00:00,  4.97epoch/s, loss=0.00343, prev_loss=0.00389]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.19ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.29s seconds\n",
      "[I 2025-03-05 09:50:05,080] Trial 430 finished with value: 0.12682735919952393 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.02806998132629811, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1700040312.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:39<00:00,  5.00epoch/s, loss=0.00132, prev_loss=0.00207]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.38ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 09:51:45,555] Trial 431 finished with value: 0.15821269154548645 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.052890285418737616, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 347045232.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [00:59<00:00,  5.03epoch/s, loss=0.0025, prev_loss=0.00286] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.36ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 09:52:45,592] Trial 432 finished with value: 0.1495339423418045 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05639814609887791, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1940411234.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:45<00:00,  4.75epoch/s, loss=0.000659, prev_loss=0.00077] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.63ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.38s seconds\n",
      "[I 2025-03-05 09:54:31,450] Trial 433 finished with value: 0.12650206685066223 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.05394664838201974, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 154164483.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:42<00:00,  4.89epoch/s, loss=0.00154, prev_loss=0.00137]  \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.33ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 09:56:14,157] Trial 434 finished with value: 0.14496317505836487 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05448658794982508, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 758027599.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [01:30<00:00,  3.31epoch/s, loss=0.0019, prev_loss=0.00163] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:01<00:00, 485triple/s] \n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 1.26s seconds\n",
      "[I 2025-03-05 09:57:46,500] Trial 435 finished with value: 0.05697641894221306 and parameters: {'model.embedding_dim': 224, 'optimizer.lr': 0.051767498675856394, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 158121125.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:21<00:00,  4.91epoch/s, loss=0.00205, prev_loss=0.00257]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 3.29ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n",
      "[I 2025-03-05 09:59:08,350] Trial 436 finished with value: 0.14196963608264923 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04772028896634133, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1847037591.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 600/600 [02:06<00:00,  4.76epoch/s, loss=0.000894, prev_loss=0.00085] \n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.02ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.31s seconds\n",
      "[I 2025-03-05 10:01:15,026] Trial 437 finished with value: 0.1337500363588333 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.051345011308780435, 'training.num_epochs': 600}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1779145850.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 500/500 [01:54<00:00,  4.36epoch/s, loss=0.000944, prev_loss=0.000856]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.51ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.41s seconds\n",
      "[I 2025-03-05 10:03:10,355] Trial 438 finished with value: 0.1373388171195984 and parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.04923018320742516, 'training.num_epochs': 500}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 490562013.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 200/200 [00:39<00:00,  5.10epoch/s, loss=0.00764, prev_loss=0.00539]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.47ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.25s seconds\n",
      "[I 2025-03-05 10:03:50,086] Trial 439 finished with value: 0.10581287741661072 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.04505702518738445, 'training.num_epochs': 200}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 459037208.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 400/400 [01:15<00:00,  5.28epoch/s, loss=0.00194, prev_loss=0.00148]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 2.30ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.27s seconds\n",
      "[I 2025-03-05 10:05:06,230] Trial 440 finished with value: 0.1413191258907318 and parameters: {'model.embedding_dim': 16, 'optimizer.lr': 0.05250599252135586, 'training.num_epochs': 400}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 862324222.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu: 100%|██████████| 300/300 [01:13<00:00,  4.10epoch/s, loss=0.00144, prev_loss=0.00157]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/604 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 604/604 [00:00<00:00, 1.31ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.47s seconds\n",
      "[I 2025-03-05 10:06:20,080] Trial 441 finished with value: 0.12796390056610107 and parameters: {'model.embedding_dim': 48, 'optimizer.lr': 0.055547393149714124, 'training.num_epochs': 300}. Best is trial 108 with value: 0.17843475937843323.\n",
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 2121409832.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu:  59%|█████▉    | 295/500 [01:02<00:43,  4.73epoch/s, loss=0.0121, prev_loss=0.0105]\n",
      "[W 2025-03-05 10:07:22,709] Trial 442 failed with parameters: {'model.embedding_dim': 32, 'optimizer.lr': 0.02122100889135834, 'training.num_epochs': 500} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/hpo/hpo.py\", line 265, in __call__\n",
      "    result = pipeline(\n",
      "        # 1. Dataset\n",
      "    ...<42 lines>...\n",
      "        device=self.device,\n",
      "    )\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/pipeline/api.py\", line 1540, in pipeline\n",
      "    stopper_instance, configuration, losses, train_seconds = _handle_training(\n",
      "                                                             ~~~~~~~~~~~~~~~~^\n",
      "        _result_tracker=_result_tracker,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "        use_tqdm=use_tqdm,\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/pipeline/api.py\", line 1181, in _handle_training\n",
      "    losses = training_loop_instance.train(\n",
      "        triples_factory=training,\n",
      "    ...<2 lines>...\n",
      "        **training_kwargs,\n",
      "    )\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py\", line 394, in train\n",
      "    result = self._train(\n",
      "        num_epochs=num_epochs,\n",
      "    ...<25 lines>...\n",
      "        pin_memory=pin_memory,\n",
      "    )\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py\", line 727, in _train\n",
      "    epoch_loss = self._train_epoch(\n",
      "        batches=batches,\n",
      "    ...<5 lines>...\n",
      "        only_size_probing=only_size_probing,\n",
      "    )\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py\", line 487, in _train_epoch\n",
      "    batch_loss = self._forward_pass(\n",
      "        batch,\n",
      "    ...<5 lines>...\n",
      "        backward=backward,\n",
      "    )\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py\", line 880, in _forward_pass\n",
      "    loss.backward()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/torch/_tensor.py\", line 626, in backward\n",
      "    torch.autograd.backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        tensors,\n",
      "        ^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        accumulate_grad=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/thezamp/miniconda3/envs/krw/lib/python3.13/site-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        t_outputs, *args, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )  # Calls into the C++ engine to run the backward pass\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-05 10:07:22,798] Trial 442 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpykeen\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhpo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hpo_pipeline\n\u001b[32m      3\u001b[39m got_hpo_train, got_hpo_val = got_training.split([\u001b[32m0.8\u001b[39m,\u001b[32m0.2\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m hpo_pipeline_result = \u001b[43mhpo_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgot_hpo_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgot_hpo_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgot_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcomplEx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msLCWA\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLP\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregularizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbasic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_negs_per_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/hpo/hpo.py:874\u001b[39m, in \u001b[36mhpo_pipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, model_kwargs_ranges, loss, loss_kwargs, loss_kwargs_ranges, regularizer, regularizer_kwargs, regularizer_kwargs_ranges, optimizer, optimizer_kwargs, optimizer_kwargs_ranges, lr_scheduler, lr_scheduler_kwargs, lr_scheduler_kwargs_ranges, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, negative_sampler_kwargs_ranges, epochs, training_kwargs, training_kwargs_ranges, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, metric, filter_validation_when_testing, result_tracker, result_tracker_kwargs, device, storage, sampler, sampler_kwargs, pruner, pruner_kwargs, study_name, direction, load_if_exists, n_trials, timeout, gc_after_trial, n_jobs, save_model_directory)\u001b[39m\n\u001b[32m    818\u001b[39m objective = Objective(\n\u001b[32m    819\u001b[39m     \u001b[38;5;66;03m# 1. Dataset\u001b[39;00m\n\u001b[32m    820\u001b[39m     dataset=dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m    870\u001b[39m     device=device,\n\u001b[32m    871\u001b[39m )\n\u001b[32m    873\u001b[39m \u001b[38;5;66;03m# Invoke optimization of the objective function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m874\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTrial\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mMemoryError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HpoPipelineResult(\n\u001b[32m    884\u001b[39m     study=study,\n\u001b[32m    885\u001b[39m     objective=objective,\n\u001b[32m    886\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/hpo/hpo.py:265\u001b[39m, in \u001b[36mObjective.__call__\u001b[39m\u001b[34m(self, trial)\u001b[39m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_stopper_callbacks(_stopper_kwargs, trial, metric=\u001b[38;5;28mself\u001b[39m.metric, result_tracker=result_tracker)\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 1. Dataset\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_entity_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_relation_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 2. Model\u001b[39;49;00m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 3. Loss\u001b[39;49;00m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_loss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 4. Regularizer\u001b[39;49;00m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregularizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_regularizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5. Optimizer\u001b[39;49;00m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_optimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 5.1 Learning Rate Scheduler\u001b[39;49;00m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_lr_scheduler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 6. Training Loop\u001b[39;49;00m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_negative_sampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 7. Training\u001b[39;49;00m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_loop_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_training_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_stopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 8. Evaluation\u001b[39;49;00m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 9. Tracker\u001b[39;49;00m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult_tracker_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Misc.\u001b[39;49;00m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use validation set during HPO!\u001b[39;49;00m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    312\u001b[39m     \u001b[38;5;66;03m# close run in result tracker\u001b[39;00m\n\u001b[32m    313\u001b[39m     result_tracker.end_run(success=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/pipeline/api.py:1540\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1519\u001b[39m training_loop_instance = _handle_training_loop(\n\u001b[32m   1520\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1521\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m     negative_sampler_kwargs=negative_sampler_kwargs,\n\u001b[32m   1531\u001b[39m )\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m stopper_instance, configuration, losses, train_seconds = \u001b[43m_handle_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m metric_results, evaluate_seconds = _handle_evaluation(\n\u001b[32m   1557\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1558\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1569\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1570\u001b[39m )\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/pipeline/api.py:1181\u001b[39m, in \u001b[36m_handle_training\u001b[39m\u001b[34m(_result_tracker, training, validation, model_instance, evaluator_instance, training_loop_instance, clear_optimizer, evaluation_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, use_tqdm)\u001b[39m\n\u001b[32m   1179\u001b[39m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[32m   1180\u001b[39m training_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m losses = \u001b[43mtraining_loop_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[32m   1188\u001b[39m training_end_time = time.time() - training_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:394\u001b[39m, in \u001b[36mTrainingLoop.train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    391\u001b[39m             temporary_directory = exit_stack.enter_context(TemporaryDirectory())\n\u001b[32m    392\u001b[39m             best_epoch_model_file_path = pathlib.Path(temporary_directory).joinpath(\u001b[33m\"\u001b[39m\u001b[33mbest_model.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m            \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[32m    425\u001b[39m torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:727\u001b[39m, in \u001b[36mTrainingLoop._train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    725\u001b[39m     batches = train_data_loader\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m epoch_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m# When size probing we don't need the losses\u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:487\u001b[39m, in \u001b[36mTrainingLoop._train_epoch\u001b[39m\u001b[34m(self, batches, callbacks, sub_batch_size, label_smoothing, slice_size, epoch, only_size_probing, backward)\u001b[39m\n\u001b[32m    484\u001b[39m stop = \u001b[38;5;28mmin\u001b[39m(start + _sub_batch_size, current_batch_size)\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# forward pass call\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m batch_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m current_epoch_loss += batch_loss\n\u001b[32m    497\u001b[39m callbacks.on_batch(epoch=epoch, batch=batch, batch_loss=batch_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:880\u001b[39m, in \u001b[36mTrainingLoop._forward_pass\u001b[39m\u001b[34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size, backward)\u001b[39m\n\u001b[32m    878\u001b[39m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backward:\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m current_epoch_loss = loss.item()\n\u001b[32m    883\u001b[39m \u001b[38;5;28mself\u001b[39m.model.post_forward_pass()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# from pykeen.hpo import hpo_pipeline\n",
    "\n",
    "# got_hpo_train, got_hpo_val = got_training.split([0.8,0.2])\n",
    "# hpo_pipeline_result = hpo_pipeline(\n",
    "#     training=got_hpo_train,\n",
    "#     validation=got_hpo_val,\n",
    "#     testing=got_testing,\n",
    "#     model='complEx',\n",
    "\n",
    "#     training_loop='sLCWA',\n",
    "#     regularizer='LP', \n",
    "#     regularizer_kwargs={'p':2, 'weight':1e-5}, \n",
    "#     negative_sampler='basic',\n",
    "#     negative_sampler_kwargs=dict(\n",
    "#         filtered=True,\n",
    "#         num_negs_per_pos=5\n",
    "#     ),\n",
    "#     evaluator_kwargs=dict(\n",
    "#         filtered=True,\n",
    "#     ),\n",
    "#     training_kwargs={'batch_size': 5000}\n",
    "\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 179731729.\n",
      "WARNING:pykeen.utils:No cuda devices were available. The model runs on CPU\n",
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "Training epochs on cpu:   7%|▋         | 28/400 [00:07<01:45,  3.53epoch/s, loss=3.73, prev_loss=3.91]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpykeen\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Kinships, Countries, AristoV4, Nations\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# dataset = Nations()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m pipeline_result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mComplEx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgot_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgot_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m0.033\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#loss= 'Negative Log Likelihood',\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# loss='pairwisehinge', \u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# loss_kwargs={'margin': 0.5},\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNegative Log Likelihood Loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLP\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregularizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbasic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_negs_per_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(pipeline_result.get_metric(\u001b[33m'\u001b[39m\u001b[33mmrr\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(pipeline_result.get_metric(\u001b[33m'\u001b[39m\u001b[33mhits@10\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/pipeline/api.py:1540\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1519\u001b[39m training_loop_instance = _handle_training_loop(\n\u001b[32m   1520\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1521\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m     negative_sampler_kwargs=negative_sampler_kwargs,\n\u001b[32m   1531\u001b[39m )\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m stopper_instance, configuration, losses, train_seconds = \u001b[43m_handle_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m metric_results, evaluate_seconds = _handle_evaluation(\n\u001b[32m   1557\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1558\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1569\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1570\u001b[39m )\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/pipeline/api.py:1181\u001b[39m, in \u001b[36m_handle_training\u001b[39m\u001b[34m(_result_tracker, training, validation, model_instance, evaluator_instance, training_loop_instance, clear_optimizer, evaluation_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, use_tqdm)\u001b[39m\n\u001b[32m   1179\u001b[39m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[32m   1180\u001b[39m training_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m losses = \u001b[43mtraining_loop_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[32m   1188\u001b[39m training_end_time = time.time() - training_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:394\u001b[39m, in \u001b[36mTrainingLoop.train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    391\u001b[39m             temporary_directory = exit_stack.enter_context(TemporaryDirectory())\n\u001b[32m    392\u001b[39m             best_epoch_model_file_path = pathlib.Path(temporary_directory).joinpath(\u001b[33m\"\u001b[39m\u001b[33mbest_model.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m            \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[32m    425\u001b[39m torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:727\u001b[39m, in \u001b[36mTrainingLoop._train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    725\u001b[39m     batches = train_data_loader\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m epoch_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m# When size probing we don't need the losses\u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:487\u001b[39m, in \u001b[36mTrainingLoop._train_epoch\u001b[39m\u001b[34m(self, batches, callbacks, sub_batch_size, label_smoothing, slice_size, epoch, only_size_probing, backward)\u001b[39m\n\u001b[32m    484\u001b[39m stop = \u001b[38;5;28mmin\u001b[39m(start + _sub_batch_size, current_batch_size)\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# forward pass call\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m batch_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m current_epoch_loss += batch_loss\n\u001b[32m    497\u001b[39m callbacks.on_batch(epoch=epoch, batch=batch, batch_loss=batch_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/pykeen/training/training_loop.py:880\u001b[39m, in \u001b[36mTrainingLoop._forward_pass\u001b[39m\u001b[34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size, backward)\u001b[39m\n\u001b[32m    878\u001b[39m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backward:\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m current_epoch_loss = loss.item()\n\u001b[32m    883\u001b[39m \u001b[38;5;28mself\u001b[39m.model.post_forward_pass()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/krw/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from pykeen.datasets import Kinships, Countries, AristoV4, Nations\n",
    "# dataset = Nations()\n",
    "pipeline_result = pipeline(\n",
    "    model='ComplEx',\n",
    "    training=got_training,\n",
    "    testing=got_testing,\n",
    "    epochs=400,\n",
    "    dimensions=16,\n",
    "    optimizer_kwargs={'lr':0.033\n",
    "                      },\n",
    "    #loss= 'Negative Log Likelihood',\n",
    "    # loss='pairwisehinge', \n",
    "    # loss_kwargs={'margin': 0.5},\n",
    "    loss = 'Negative Log Likelihood Loss',\n",
    "    regularizer='LP', \n",
    "    regularizer_kwargs={'p':2, 'weight':1e-5}, \n",
    "    \n",
    "    negative_sampler='basic',\n",
    "    negative_sampler_kwargs=dict(\n",
    "        filtered=True,\n",
    "        num_negs_per_pos=5\n",
    "    ),\n",
    "    evaluator_kwargs=dict(\n",
    "        filtered=True,\n",
    "    ),\n",
    "    training_kwargs={'batch_size': 5000}\n",
    ")\n",
    "print(pipeline_result.get_metric('mrr'))\n",
    "print(pipeline_result.get_metric('hits@10'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Eddard Stark'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     15\u001b[39m people = [\u001b[33m'\u001b[39m\u001b[33mEddard Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mArya Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mJon Snow\u001b[39m\u001b[33m'\u001b[39m,  \n\u001b[32m     16\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mSansa Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mBrandon Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRickon Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatelyn Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRobb Stark\u001b[39m\u001b[33m'\u001b[39m,  \n\u001b[32m     17\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mBenjen Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLyanna Stark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTheon Greyjoy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mBalon Greyjoy\u001b[39m\u001b[33m'\u001b[39m,  \n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mOberyn Nymeros Martell\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEllaria Sand\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDoran Martell\u001b[39m\u001b[33m'\u001b[39m,   \n\u001b[32m     23\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mJorah Mormont\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mJeor Mormont\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     24\u001b[39m houses = [\u001b[33m'\u001b[39m\u001b[33mHouse Stark of Winterfell\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHouse Lannister of Casterly Rock\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mHouse Targaryen of King\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms Landing\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m   \u001b[33m'\u001b[39m\u001b[33mHouse Baratheon of Dragonstone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHouse Tyrell of Highgarden\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHouse Greyjoy of Pyke\u001b[39m\u001b[33m'\u001b[39m]  \n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m ids = [\u001b[43mentity_to_id\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m people + houses]\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, entity \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids, people + houses):\n\u001b[32m     31\u001b[39m     plt.plot(eu[:, \u001b[32m0\u001b[39m], eu[:, \u001b[32m1\u001b[39m],\u001b[33m'\u001b[39m\u001b[33m.b\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'Eddard Stark'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pipeline_result.model\n",
    "# entity_to_id = dataset.entity_to_id\n",
    "# relation_to_id = dataset.relation_to_id\n",
    "entity_to_id = got_training.entity_to_id\n",
    "relation_to_id = got_training.relation_to_id\n",
    "plt.figure(figsize=(10, 10))\n",
    "pca = PCA(n_components=2)\n",
    "entity_embeddings = np.hstack([model.entity_representations[0](indices=None).detach().numpy().real, model.entity_representations[0](indices=None).detach().numpy().imag])\n",
    "#entity_embeddings =model.entity_representations[0](indices=None).detach().numpy().real\n",
    "m = pca.fit(entity_embeddings)\n",
    "\n",
    "eu = m.transform(entity_embeddings)\n",
    "\n",
    "\n",
    "people = ['Eddard Stark', 'Arya Stark', 'Jon Snow',  \n",
    " 'Sansa Stark', 'Brandon Stark', 'Rickon Stark', 'Catelyn Stark', 'Robb Stark',  \n",
    " 'Benjen Stark', 'Lyanna Stark', 'Theon Greyjoy', 'Balon Greyjoy',  \n",
    " 'Daenerys Targaryen', 'Viserys Targaryen', 'Aegon Targaryen', 'Rhaegar Targaryen',  \n",
    " 'Tyrion Lannister', 'Jaime Lannister', 'Cersei Lannister', 'Tywin Lannister',  \n",
    " 'Kevan Lannister', 'Lancel Lannister', 'Joffrey Baratheon', 'Tommen Baratheon',  \n",
    " 'Stannis Baratheon', 'Renly Baratheon', 'Robert I Baratheon',  \n",
    " 'Oberyn Nymeros Martell', 'Ellaria Sand', 'Doran Martell',   \n",
    " 'Jorah Mormont', 'Jeor Mormont']\n",
    "houses = ['House Stark of Winterfell', 'House Lannister of Casterly Rock',\"House Targaryen of King's Landing\",\n",
    "  'House Baratheon of Dragonstone', 'House Tyrell of Highgarden', 'House Greyjoy of Pyke']  \n",
    "\n",
    "\n",
    "ids = [entity_to_id[name] for name in people + houses]\n",
    "for i, entity in zip(ids, people + houses):\n",
    "    \n",
    "    plt.plot(eu[:, 0], eu[:, 1],'.b')\n",
    "    plt.annotate(\n",
    "        text=entity,\n",
    "        xy=(eu[i, 0], eu[i, 1]),\n",
    "        color=\"tab:blue\",\n",
    "        ha=\"center\", va=\"top\"\n",
    "    )\n",
    "\n",
    "\n",
    "# relation_embeddings = np.hstack([model.relation_representations[0](indices=None).detach().numpy().real, model.relation_representations[0](indices=None).detach().numpy().imag])\n",
    "# #relation_embeddings = model.relation_representations[0](indices=None).detach().numpy().real\n",
    "# ru = pca.transform(relation_embeddings)\n",
    "# for i, relation in enumerate(relation_to_id):\n",
    "#    if i <10:\n",
    "#         plt.annotate(\n",
    "#             text=relation,\n",
    "#             xy=(0,0), xytext=(ru[i, 0], ru[i, 1]),\n",
    "#             arrowprops=dict(\n",
    "#                 arrowstyle=\"<-\",\n",
    "#                 color=\"tab:red\",\n",
    "#                 shrinkA=5,\n",
    "#                 shrinkB=5,\n",
    "#                 patchA=None,\n",
    "#                 patchB=None,\n",
    "#                 connectionstyle=\"arc3,rad=0.\"\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "lim = 6\n",
    "plt.xlim([-lim, lim])\n",
    "plt.ylim([-lim, lim])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Eddard Stark'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mentity_to_id\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEddard Stark\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'Eddard Stark'"
     ]
    }
   ],
   "source": [
    "entity_to_id['Eddard Stark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 More Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorboard](https://www.tensorflow.org/tensorboard) allows to dig into the workings of our model, plot how it is learning, and visualize [high-dimensional embeddings](https://projector.tensorflow.org/). See [this tutorial](https://www.tensorflow.org/tensorboard/get_started) to get started with Tensorflow and see [here](https://pykeen.readthedocs.io/en/stable/tutorial/trackers/using_tensorboard.html) for Tensorboard with PyKEEN.\n",
    "\n",
    "First ytou neeed to start the tensorboard web application from the command line with \n",
    "\n",
    "$ tensorboard --logdir=~/.data/pykeen/logs/tensorboard/\n",
    "\n",
    "and then we can add tensorboard as the result_tracker in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 74.01batch/s]\u001b[A\n",
      "Training epochs on cpu:  45%|█████████▍           | 90/200 [00:30<00:35,  3.07epoch/s, loss=1.47, prev_loss=1.47]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 64.25batch/s]\u001b[A\n",
      "Training epochs on cpu:  46%|█████████▌           | 91/200 [00:30<00:35,  3.06epoch/s, loss=1.67, prev_loss=1.47]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 63.01batch/s]\u001b[A\n",
      "Training epochs on cpu:  46%|█████████▋           | 92/200 [00:31<00:36,  2.96epoch/s, loss=1.33, prev_loss=1.67]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.24batch/s]\u001b[A\n",
      "Training epochs on cpu:  46%|█████████▊           | 93/200 [00:31<00:37,  2.89epoch/s, loss=1.34, prev_loss=1.33]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.56batch/s]\u001b[A\n",
      "Training epochs on cpu:  47%|█████████▊           | 94/200 [00:31<00:37,  2.82epoch/s, loss=1.18, prev_loss=1.34]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 64.46batch/s]\u001b[A\n",
      "Training epochs on cpu:  48%|█████████▉           | 95/200 [00:32<00:37,  2.80epoch/s, loss=1.09, prev_loss=1.18]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.86batch/s]\u001b[A\n",
      "Training epochs on cpu:  48%|██████████           | 96/200 [00:32<00:37,  2.77epoch/s, loss=1.14, prev_loss=1.09]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 68.47batch/s]\u001b[A\n",
      "Training epochs on cpu:  48%|██████████▋           | 97/200 [00:33<00:35,  2.86epoch/s, loss=1.3, prev_loss=1.14]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.27batch/s]\u001b[A\n",
      "Training epochs on cpu:  49%|██████████▎          | 98/200 [00:33<00:36,  2.80epoch/s, loss=0.958, prev_loss=1.3]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.10batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.59batch/s]\u001b[A\n",
      "Training epochs on cpu:  50%|█████████▉          | 99/200 [00:33<00:36,  2.78epoch/s, loss=1.17, prev_loss=0.958]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.70batch/s]\u001b[A\n",
      "Training epochs on cpu:  50%|██████████          | 100/200 [00:34<00:36,  2.73epoch/s, loss=1.13, prev_loss=1.17]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.45batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.80batch/s]\u001b[A\n",
      "Training epochs on cpu:  50%|██████████          | 101/200 [00:34<00:37,  2.67epoch/s, loss=1.18, prev_loss=1.13]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.85batch/s]\u001b[A\n",
      "Training epochs on cpu:  51%|██████████▏         | 102/200 [00:34<00:36,  2.67epoch/s, loss=1.09, prev_loss=1.18]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.62batch/s]\u001b[A\n",
      "Training epochs on cpu:  52%|██████████▎         | 103/200 [00:35<00:36,  2.68epoch/s, loss=1.04, prev_loss=1.09]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 57.76batch/s]\u001b[A\n",
      "Training epochs on cpu:  52%|█████████▉         | 104/200 [00:35<00:36,  2.65epoch/s, loss=0.987, prev_loss=1.04]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 68.73batch/s]\u001b[A\n",
      "Training epochs on cpu:  52%|█████████▉         | 105/200 [00:36<00:35,  2.70epoch/s, loss=1.09, prev_loss=0.987]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.13batch/s]\u001b[A\n",
      "Training epochs on cpu:  53%|██████████         | 106/200 [00:36<00:34,  2.70epoch/s, loss=0.955, prev_loss=1.09]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.69batch/s]\u001b[A\n",
      "Training epochs on cpu:  54%|██████████▏        | 107/200 [00:36<00:34,  2.68epoch/s, loss=1.01, prev_loss=0.955]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 53.86batch/s]\u001b[A\n",
      "Training epochs on cpu:  54%|██████████▊         | 108/200 [00:37<00:34,  2.65epoch/s, loss=1.12, prev_loss=1.01]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 54.01batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.52batch/s]\u001b[A\n",
      "Training epochs on cpu:  55%|██████████▉         | 109/200 [00:37<00:35,  2.60epoch/s, loss=1.14, prev_loss=1.12]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.06batch/s]\u001b[A\n",
      "Training epochs on cpu:  55%|███████████▌         | 110/200 [00:37<00:34,  2.58epoch/s, loss=0.9, prev_loss=1.14]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 58.75batch/s]\u001b[A\n",
      "Training epochs on cpu:  56%|███████████▋         | 111/200 [00:38<00:33,  2.67epoch/s, loss=1.11, prev_loss=0.9]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.35batch/s]\u001b[A\n",
      "Training epochs on cpu:  56%|██████████▋        | 112/200 [00:38<00:32,  2.73epoch/s, loss=0.971, prev_loss=1.11]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.23batch/s]\u001b[A\n",
      "Training epochs on cpu:  56%|██████████▏       | 113/200 [00:38<00:31,  2.77epoch/s, loss=0.922, prev_loss=0.971]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.31batch/s]\u001b[A\n",
      "Training epochs on cpu:  57%|██████████▎       | 114/200 [00:39<00:30,  2.86epoch/s, loss=0.926, prev_loss=0.922]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 64.44batch/s]\u001b[A\n",
      "Training epochs on cpu:  57%|██████████▎       | 115/200 [00:39<00:29,  2.84epoch/s, loss=0.965, prev_loss=0.926]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.68batch/s]\u001b[A\n",
      "Training epochs on cpu:  58%|██████████▍       | 116/200 [00:40<00:29,  2.83epoch/s, loss=0.999, prev_loss=0.965]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.91batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.63batch/s]\u001b[A\n",
      "Training epochs on cpu:  58%|██████████▌       | 117/200 [00:40<00:29,  2.77epoch/s, loss=0.824, prev_loss=0.999]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.99batch/s]\u001b[A\n",
      "Training epochs on cpu:  59%|███████████▏       | 118/200 [00:40<00:29,  2.78epoch/s, loss=0.71, prev_loss=0.824]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.93batch/s]\u001b[A\n",
      "Training epochs on cpu:  60%|███████████▎       | 119/200 [00:41<00:29,  2.75epoch/s, loss=0.921, prev_loss=0.71]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.81batch/s]\u001b[A\n",
      "Training epochs on cpu:  60%|██████████▊       | 120/200 [00:41<00:29,  2.74epoch/s, loss=0.733, prev_loss=0.921]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.82batch/s]\u001b[A\n",
      "Training epochs on cpu:  60%|██████████▉       | 121/200 [00:41<00:28,  2.79epoch/s, loss=0.815, prev_loss=0.733]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.26batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.89batch/s]\u001b[A\n",
      "Training epochs on cpu:  61%|██████████▉       | 122/200 [00:42<00:28,  2.73epoch/s, loss=0.793, prev_loss=0.815]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 56.93batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.74batch/s]\u001b[A\n",
      "Training epochs on cpu:  62%|███████████▋       | 123/200 [00:42<00:28,  2.69epoch/s, loss=0.65, prev_loss=0.793]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 56.06batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.69batch/s]\u001b[A\n",
      "Training epochs on cpu:  62%|███████████▊       | 124/200 [00:42<00:28,  2.65epoch/s, loss=0.761, prev_loss=0.65]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.39batch/s]\u001b[A\n",
      "Training epochs on cpu:  62%|███████████▎      | 125/200 [00:43<00:28,  2.65epoch/s, loss=0.805, prev_loss=0.761]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.63batch/s]\u001b[A\n",
      "Training epochs on cpu:  63%|███████████▎      | 126/200 [00:43<00:27,  2.66epoch/s, loss=0.707, prev_loss=0.805]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.41batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.75batch/s]\u001b[A\n",
      "Training epochs on cpu:  64%|███████████▍      | 127/200 [00:44<00:27,  2.65epoch/s, loss=0.718, prev_loss=0.707]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.51batch/s]\u001b[A\n",
      "Training epochs on cpu:  64%|███████████▌      | 128/200 [00:44<00:26,  2.73epoch/s, loss=0.721, prev_loss=0.718]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.26batch/s]\u001b[A\n",
      "Training epochs on cpu:  64%|███████████▌      | 129/200 [00:44<00:25,  2.74epoch/s, loss=0.684, prev_loss=0.721]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 76.17batch/s]\u001b[A\n",
      "Training epochs on cpu:  65%|███████████▋      | 130/200 [00:45<00:24,  2.82epoch/s, loss=0.599, prev_loss=0.684]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.30batch/s]\u001b[A\n",
      "Training epochs on cpu:  66%|███████████▊      | 131/200 [00:45<00:24,  2.83epoch/s, loss=0.665, prev_loss=0.599]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.65batch/s]\u001b[A\n",
      "Training epochs on cpu:  66%|███████████▉      | 132/200 [00:45<00:24,  2.82epoch/s, loss=0.842, prev_loss=0.665]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 63.66batch/s]\u001b[A\n",
      "Training epochs on cpu:  66%|███████████▉      | 133/200 [00:46<00:23,  2.81epoch/s, loss=0.518, prev_loss=0.842]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.53batch/s]\u001b[A\n",
      "Training epochs on cpu:  67%|████████████      | 134/200 [00:46<00:22,  2.87epoch/s, loss=0.575, prev_loss=0.518]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 66.82batch/s]\u001b[A\n",
      "Training epochs on cpu:  68%|████████████▏     | 135/200 [00:46<00:22,  2.89epoch/s, loss=0.517, prev_loss=0.575]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 66.80batch/s]\u001b[A\n",
      "Training epochs on cpu:  68%|████████████▏     | 136/200 [00:47<00:22,  2.88epoch/s, loss=0.658, prev_loss=0.517]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 63.59batch/s]\u001b[A\n",
      "Training epochs on cpu:  68%|████████████▎     | 137/200 [00:47<00:21,  2.87epoch/s, loss=0.725, prev_loss=0.658]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.23batch/s]\u001b[A\n",
      "Training epochs on cpu:  69%|████████████▍     | 138/200 [00:47<00:21,  2.87epoch/s, loss=0.499, prev_loss=0.725]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.85batch/s]\u001b[A\n",
      "Training epochs on cpu:  70%|█████████████▏     | 139/200 [00:48<00:21,  2.84epoch/s, loss=0.67, prev_loss=0.499]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.20batch/s]\u001b[A\n",
      "Training epochs on cpu:  70%|█████████████▎     | 140/200 [00:48<00:21,  2.84epoch/s, loss=0.591, prev_loss=0.67]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.64batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.18batch/s]\u001b[A\n",
      "Training epochs on cpu:  70%|████████████▋     | 141/200 [00:49<00:21,  2.77epoch/s, loss=0.552, prev_loss=0.591]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.09batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.55batch/s]\u001b[A\n",
      "Training epochs on cpu:  71%|████████████▊     | 142/200 [00:49<00:20,  2.77epoch/s, loss=0.564, prev_loss=0.552]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 58.35batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.02batch/s]\u001b[A\n",
      "Training epochs on cpu:  72%|████████████▊     | 143/200 [00:49<00:20,  2.74epoch/s, loss=0.539, prev_loss=0.564]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.38batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.93batch/s]\u001b[A\n",
      "Training epochs on cpu:  72%|████████████▉     | 144/200 [00:50<00:20,  2.70epoch/s, loss=0.513, prev_loss=0.539]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.61batch/s]\u001b[A\n",
      "Training epochs on cpu:  72%|█████████████     | 145/200 [00:50<00:20,  2.69epoch/s, loss=0.558, prev_loss=0.513]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 54.71batch/s]\u001b[A\n",
      "Training epochs on cpu:  73%|█████████████▏    | 146/200 [00:50<00:20,  2.66epoch/s, loss=0.546, prev_loss=0.558]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.15batch/s]\u001b[A\n",
      "Training epochs on cpu:  74%|█████████████▏    | 147/200 [00:51<00:19,  2.66epoch/s, loss=0.598, prev_loss=0.546]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.72batch/s]\u001b[A\n",
      "Training epochs on cpu:  74%|█████████████▎    | 148/200 [00:51<00:19,  2.66epoch/s, loss=0.501, prev_loss=0.598]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.93batch/s]\u001b[A\n",
      "Training epochs on cpu:  74%|█████████████▍    | 149/200 [00:52<00:18,  2.73epoch/s, loss=0.456, prev_loss=0.501]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 67.13batch/s]\u001b[A\n",
      "Training epochs on cpu:  75%|█████████████▌    | 150/200 [00:52<00:17,  2.80epoch/s, loss=0.478, prev_loss=0.456]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 64.55batch/s]\u001b[A\n",
      "Training epochs on cpu:  76%|█████████████▌    | 151/200 [00:52<00:17,  2.85epoch/s, loss=0.454, prev_loss=0.478]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.78batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.81batch/s]\u001b[A\n",
      "Training epochs on cpu:  76%|██████████████▍    | 152/200 [00:53<00:17,  2.74epoch/s, loss=0.46, prev_loss=0.454]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.84batch/s]\u001b[A\n",
      "Training epochs on cpu:  76%|██████████████▌    | 153/200 [00:53<00:16,  2.85epoch/s, loss=0.553, prev_loss=0.46]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 69.21batch/s]\u001b[A\n",
      "Training epochs on cpu:  77%|█████████████▊    | 154/200 [00:53<00:15,  2.94epoch/s, loss=0.483, prev_loss=0.553]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 70.46batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs on cpu:  78%|█████████████▉    | 155/200 [00:54<00:15,  2.94epoch/s, loss=0.462, prev_loss=0.483]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.83batch/s]\u001b[A\n",
      "Training epochs on cpu:  78%|██████████████    | 156/200 [00:54<00:15,  2.90epoch/s, loss=0.561, prev_loss=0.462]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 67.28batch/s]\u001b[A\n",
      "Training epochs on cpu:  78%|██████████████▏   | 157/200 [00:54<00:14,  2.90epoch/s, loss=0.507, prev_loss=0.561]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 74.73batch/s]\u001b[A\n",
      "Training epochs on cpu:  79%|██████████████▏   | 158/200 [00:55<00:14,  2.94epoch/s, loss=0.484, prev_loss=0.507]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 63.55batch/s]\u001b[A\n",
      "Training epochs on cpu:  80%|██████████████▎   | 159/200 [00:55<00:13,  2.95epoch/s, loss=0.401, prev_loss=0.484]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 73.10batch/s]\u001b[A\n",
      "Training epochs on cpu:  80%|██████████████▍   | 160/200 [00:55<00:13,  3.03epoch/s, loss=0.457, prev_loss=0.401]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 71.25batch/s]\u001b[A\n",
      "Training epochs on cpu:  80%|██████████████▍   | 161/200 [00:56<00:12,  3.07epoch/s, loss=0.356, prev_loss=0.457]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.75batch/s]\u001b[A\n",
      "Training epochs on cpu:  81%|██████████████▌   | 162/200 [00:56<00:12,  2.98epoch/s, loss=0.344, prev_loss=0.356]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 69.06batch/s]\u001b[A\n",
      "Training epochs on cpu:  82%|██████████████▋   | 163/200 [00:56<00:12,  2.97epoch/s, loss=0.448, prev_loss=0.344]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 72.50batch/s]\u001b[A\n",
      "Training epochs on cpu:  82%|██████████████▊   | 164/200 [00:57<00:12,  2.98epoch/s, loss=0.454, prev_loss=0.448]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.86batch/s]\u001b[A\n",
      "Training epochs on cpu:  82%|██████████████▊   | 165/200 [00:57<00:11,  2.98epoch/s, loss=0.283, prev_loss=0.454]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.30batch/s]\u001b[A\n",
      "Training epochs on cpu:  83%|██████████████▉   | 166/200 [00:57<00:11,  2.88epoch/s, loss=0.422, prev_loss=0.283]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 59.85batch/s]\u001b[A\n",
      "Training epochs on cpu:  84%|███████████████   | 167/200 [00:58<00:11,  2.86epoch/s, loss=0.377, prev_loss=0.422]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.29batch/s]\u001b[A\n",
      "Training epochs on cpu:  84%|███████████████   | 168/200 [00:58<00:11,  2.86epoch/s, loss=0.395, prev_loss=0.377]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.23batch/s]\u001b[A\n",
      "Training epochs on cpu:  84%|███████████████▏  | 169/200 [00:58<00:11,  2.80epoch/s, loss=0.448, prev_loss=0.395]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 62.37batch/s]\u001b[A\n",
      "Training epochs on cpu:  85%|████████████████▏  | 170/200 [00:59<00:10,  2.76epoch/s, loss=0.44, prev_loss=0.448]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.01batch/s]\u001b[A\n",
      "Training epochs on cpu:  86%|█████████████████   | 171/200 [00:59<00:10,  2.72epoch/s, loss=0.38, prev_loss=0.44]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.22batch/s]\u001b[A\n",
      "Training epochs on cpu:  86%|████████████████▎  | 172/200 [00:59<00:10,  2.75epoch/s, loss=0.449, prev_loss=0.38]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.27batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.19batch/s]\u001b[A\n",
      "Training epochs on cpu:  86%|███████████████▌  | 173/200 [01:00<00:09,  2.76epoch/s, loss=0.333, prev_loss=0.449]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 65.26batch/s]\u001b[A\n",
      "Training epochs on cpu:  87%|███████████████▋  | 174/200 [01:00<00:09,  2.75epoch/s, loss=0.419, prev_loss=0.333]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 55.74batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 48.32batch/s]\u001b[A\n",
      "Training epochs on cpu:  88%|███████████████▊  | 175/200 [01:01<00:09,  2.59epoch/s, loss=0.358, prev_loss=0.419]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 58.49batch/s]\u001b[A\n",
      "Training epochs on cpu:  88%|███████████████▊  | 176/200 [01:01<00:09,  2.63epoch/s, loss=0.395, prev_loss=0.358]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 61.22batch/s]\u001b[A\n",
      "Training epochs on cpu:  88%|███████████████▉  | 177/200 [01:01<00:08,  2.64epoch/s, loss=0.423, prev_loss=0.395]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 59.20batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.56batch/s]\u001b[A\n",
      "Training epochs on cpu:  89%|████████████████▉  | 178/200 [01:02<00:08,  2.63epoch/s, loss=0.41, prev_loss=0.423]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  42%|████████████████████▍                            | 5/12 [00:00<00:00, 48.27batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|████████████████████████████████████████        | 10/12 [00:00<00:00, 49.14batch/s]\u001b[A\n",
      "Training epochs on cpu:  90%|█████████████████  | 179/200 [01:02<00:08,  2.50epoch/s, loss=0.321, prev_loss=0.41]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 51.94batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 49.10batch/s]\u001b[A\n",
      "Training epochs on cpu:  90%|████████████████▏ | 180/200 [01:03<00:08,  2.40epoch/s, loss=0.276, prev_loss=0.321]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  42%|████████████████████▍                            | 5/12 [00:00<00:00, 49.90batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|████████████████████████████████████████████    | 11/12 [00:00<00:00, 52.62batch/s]\u001b[A\n",
      "Training epochs on cpu:  90%|████████████████▎ | 181/200 [01:03<00:07,  2.42epoch/s, loss=0.391, prev_loss=0.276]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 57.37batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.04batch/s]\u001b[A\n",
      "Training epochs on cpu:  91%|████████████████▍ | 182/200 [01:03<00:07,  2.50epoch/s, loss=0.301, prev_loss=0.391]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 63.78batch/s]\u001b[A\n",
      "Training epochs on cpu:  92%|████████████████▍ | 183/200 [01:04<00:06,  2.57epoch/s, loss=0.304, prev_loss=0.301]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 52.40batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.94batch/s]\u001b[A\n",
      "Training epochs on cpu:  92%|████████████████▌ | 184/200 [01:04<00:06,  2.50epoch/s, loss=0.345, prev_loss=0.304]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 50.73batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.61batch/s]\u001b[A\n",
      "Training epochs on cpu:  92%|████████████████▋ | 185/200 [01:05<00:06,  2.45epoch/s, loss=0.373, prev_loss=0.345]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 56.57batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.78batch/s]\u001b[A\n",
      "Training epochs on cpu:  93%|████████████████▋ | 186/200 [01:05<00:05,  2.49epoch/s, loss=0.338, prev_loss=0.373]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 54.94batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 49.97batch/s]\u001b[A\n",
      "Training epochs on cpu:  94%|████████████████▊ | 187/200 [01:05<00:05,  2.42epoch/s, loss=0.288, prev_loss=0.338]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  42%|████████████████████▍                            | 5/12 [00:00<00:00, 46.70batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|████████████████████████████████████████        | 10/12 [00:00<00:00, 43.69batch/s]\u001b[A\n",
      "Training epochs on cpu:  94%|████████████████▉ | 188/200 [01:06<00:05,  2.32epoch/s, loss=0.358, prev_loss=0.288]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  25%|████████████▎                                    | 3/12 [00:00<00:00, 25.71batch/s]\u001b[A\n",
      "Training batches on cpu:  67%|████████████████████████████████▋                | 8/12 [00:00<00:00, 34.52batch/s]\u001b[A\n",
      "Training epochs on cpu:  94%|█████████████████▉ | 189/200 [01:06<00:04,  2.21epoch/s, loss=0.32, prev_loss=0.358]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 53.26batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.51batch/s]\u001b[A\n",
      "Training epochs on cpu:  95%|██████████████████ | 190/200 [01:07<00:04,  2.23epoch/s, loss=0.324, prev_loss=0.32]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  42%|████████████████████▍                            | 5/12 [00:00<00:00, 40.06batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|████████████████████████████████████████████    | 11/12 [00:00<00:00, 46.45batch/s]\u001b[A\n",
      "Training epochs on cpu:  96%|█████████████████▏| 191/200 [01:07<00:04,  2.18epoch/s, loss=0.265, prev_loss=0.324]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  42%|████████████████████▍                            | 5/12 [00:00<00:00, 47.03batch/s]\u001b[A\n",
      "Training batches on cpu:  92%|████████████████████████████████████████████    | 11/12 [00:00<00:00, 49.32batch/s]\u001b[A\n",
      "Training epochs on cpu:  96%|█████████████████▎| 192/200 [01:08<00:03,  2.20epoch/s, loss=0.286, prev_loss=0.265]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 51.57batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.25batch/s]\u001b[A\n",
      "Training epochs on cpu:  96%|█████████████████▎| 193/200 [01:08<00:03,  2.23epoch/s, loss=0.245, prev_loss=0.286]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  33%|████████████████▎                                | 4/12 [00:00<00:00, 38.51batch/s]\u001b[A\n",
      "Training batches on cpu:  75%|████████████████████████████████████▊            | 9/12 [00:00<00:00, 43.02batch/s]\u001b[A\n",
      "Training epochs on cpu:  97%|█████████████████▍| 194/200 [01:09<00:02,  2.21epoch/s, loss=0.223, prev_loss=0.245]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 52.38batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.12batch/s]\u001b[A\n",
      "Training epochs on cpu:  98%|█████████████████▌| 195/200 [01:09<00:02,  2.26epoch/s, loss=0.342, prev_loss=0.223]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 54.70batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.33batch/s]\u001b[A\n",
      "Training epochs on cpu:  98%|█████████████████▋| 196/200 [01:10<00:01,  2.31epoch/s, loss=0.199, prev_loss=0.342]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  42%|████████████████████▍                            | 5/12 [00:00<00:00, 48.84batch/s]\u001b[A\n",
      "Training batches on cpu:  83%|████████████████████████████████████████        | 10/12 [00:00<00:00, 49.46batch/s]\u001b[A\n",
      "Training epochs on cpu:  98%|█████████████████▋| 197/200 [01:10<00:01,  2.28epoch/s, loss=0.286, prev_loss=0.199]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 58.47batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.27batch/s]\u001b[A\n",
      "Training epochs on cpu:  99%|█████████████████▊| 198/200 [01:10<00:00,  2.38epoch/s, loss=0.235, prev_loss=0.286]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  58%|████████████████████████████▌                    | 7/12 [00:00<00:00, 60.20batch/s]\u001b[A\n",
      "Training epochs on cpu: 100%|█████████████████▉| 199/200 [01:11<00:00,  2.42epoch/s, loss=0.237, prev_loss=0.235]\u001b[A\n",
      "Training batches on cpu:   0%|                                                         | 0/12 [00:00<?, ?batch/s]\u001b[A\n",
      "Training batches on cpu:  50%|████████████████████████▌                        | 6/12 [00:00<00:00, 54.33batch/s]\u001b[A\n",
      "Training batches on cpu: 100%|████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.96batch/s]\u001b[A\n",
      "Training epochs on cpu: 100%|██████████████████| 200/200 [01:11<00:00,  2.79epoch/s, loss=0.275, prev_loss=0.237]\u001b[A\n",
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "Evaluating on cpu: 100%|█████████████████████████████████████████████████████| 159/159 [00:00<00:00, 919triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.19s seconds\n"
     ]
    }
   ],
   "source": [
    "pipeline_result = pipeline(\n",
    "    model='ComplEx',\n",
    "    training=got_training,\n",
    "    testing=got_testing,\n",
    "    training_kwargs=dict(\n",
    "        num_epochs=200\n",
    "    ),\n",
    "    dimensions=150,\n",
    "    optimizer='adam',\n",
    "    optimizer_kwargs={'lr':1e-3},\n",
    "    loss='pairwisehinge', \n",
    "    regularizer='LP', \n",
    "    regularizer_kwargs={'p':3, 'weight':1e-5}, \n",
    "    negative_sampler='basic',\n",
    "    negative_sampler_kwargs=dict(\n",
    "        filtered=True,\n",
    "    ),\n",
    "    result_tracker='tensorboard'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7 Your Own Data now\n",
    "\n",
    "Choose a dataset of your own. Best if it is the data you are using in your group project. \n",
    "\n",
    "- Create a training and testset. \n",
    "- Train your model to compute Knowledge Graph Embeddings, and save the best parameters model. - Predict new links over your dataset\n",
    "- Visualise the embeddings you computed \n",
    "- Optional : cluster your embeddings, [see this tutorial](https://docs.ampligraph.org/en/1.4.0/tutorials/ClusteringAndClassificationWithEmbeddings.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
